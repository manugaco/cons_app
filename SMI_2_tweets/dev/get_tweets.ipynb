{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 21:04:34.255845: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-24 21:04:34.255907: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# importing libraries and packages\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accent_rem(name):\n",
    "    '''\n",
    "    Function to remove accents from an alphanumeric string:\n",
    "    params:\n",
    "        - name: character string.\n",
    "    Output: string without accents.\n",
    "    '''\n",
    "    #Define replacements (possible accents or other special char)\n",
    "    replacements = (\n",
    "        (\"á\", \"a\"),\n",
    "        (\"é\", \"e\"),\n",
    "        (\"í\", \"i\"),\n",
    "        (\"ó\", \"o\"),\n",
    "        (\"ú\", \"u\"),\n",
    "        (\"ñ\", 'n'),\n",
    "        (\"à\", \"a\"),\n",
    "        (\"è\", \"e\"),\n",
    "        (\"ì\", \"i\"),\n",
    "        (\"ò\", \"o\"),\n",
    "        (\"ù\", \"u\"),\n",
    "        (\"ä\", 'a'),\n",
    "        (\"ë\", \"e\"),\n",
    "        (\"ï\", \"i\"),\n",
    "        (\"ö\", \"o\"),\n",
    "        (\"ü\", \"u\"),\n",
    "    )\n",
    "    #Replace with tuple:\n",
    "    for a, b in replacements:\n",
    "        name = name.replace(a, b).replace(a.upper(), b.upper())\n",
    "    return(name)\n",
    "\n",
    "def get_stops(stops, path):\n",
    "    \n",
    "    with open(path + stops[0]) as f:\n",
    "        stopw_1 = f.read().splitlines()\n",
    "    with open(path + stops[1]) as f:\n",
    "        stopw_2 = f.read().splitlines()\n",
    "\n",
    "    stopw_1[0] = stopw_1[0].replace('\\ufeff', '')\n",
    "    stopw = stopw_1 + stopw_2\n",
    "    stopw = [accent_rem(word) for word in stopw]\n",
    "    return(stopw)\n",
    "\n",
    "def get_ecofilter(path, files):\n",
    "    '''\n",
    "    Function to get the list of words to filter the tweets\n",
    "    '''\n",
    "    eco_filter = pd.DataFrame()\n",
    "    for file in files:\n",
    "        eco_filter = pd.concat([eco_filter, pd.read_excel(path + file, header=None)], axis=0)\n",
    "    eco_filter.drop_duplicates(inplace=True)\n",
    "    eco_filter = eco_filter.iloc[:,0].to_list()\n",
    "    #eco_filter = [lemmatize(word) for word in eco_filter]\n",
    "    return [accent_rem(word) for word in eco_filter]\n",
    "\n",
    "def remove_stops(tweet, stopw):\n",
    "    return ' '.join([word for word in tweet.split() if not word in stopw])\n",
    "\n",
    "def filter_noneco(tweet, ecolist):\n",
    "    '''\n",
    "    Function to check whether the tweet has economic topic or not:\n",
    "    params:\n",
    "        - tweet: the document itself.\n",
    "        - ecolist: list of words related to economy and politics.\n",
    "    output: the tweets if it contains at least one word in the ecolist.\n",
    "    '''\n",
    "    commons = [word for word in tweet.split() if word in ecolist]\n",
    "    if len(commons) <= 1:\n",
    "        tweet = ''\n",
    "    return tweet\n",
    "\n",
    "def get_ecotweets(df, ecolist, text_col = 'text'):\n",
    "    \n",
    "    df[text_col] = df[text_col].apply(lambda r: filter_noneco(r, ecolist))\n",
    "    df = df[df[text_col] != '']\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "def lemmatize(tweet):\n",
    "    doc = nlp(tweet)\n",
    "    lemmas = [tok.lemma_.lower() for tok in doc]\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "def trail_ws(tweet):\n",
    "    return re.sub(' +', ' ', tweet)\n",
    "\n",
    "def remove_num(tweet):\n",
    "    return ''.join([i for i in tweet if not i.isdigit()])\n",
    "\n",
    "def treat_text(df, text_col, stopw = [], ecolist = [], date_col = 'date', sent_col = 'sentiment'):\n",
    "        '''\n",
    "        Function to treat the corpus columns:\n",
    "        params:\n",
    "            - df: dataframe to treat.\n",
    "        Output: Dataframe treated.\n",
    "        '''\n",
    "        # Sanity checks:\n",
    "        df = df.fillna('')\n",
    "        \n",
    "        # Formatting corpus columns:\n",
    "\n",
    "        if date_col == 'date':\n",
    "            df[date_col] = pd.to_datetime(df[date_col])\n",
    "        if sent_col == 'sentiment':\n",
    "            df[sent_col] = df[sent_col].replace(',', '', regex=True)\n",
    "\n",
    "        #Columns treatment:\n",
    "        df[text_col] = df[text_col].apply(lambda r: ' '.join([accent_rem(name) for name in r.split()]))\n",
    "        df[text_col] = df[text_col].apply(lambda r: ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", r).split()))\n",
    "        df[text_col] = df[text_col].apply(lambda r: r.lower())\n",
    "        df[text_col] = df[text_col].apply(lambda r: remove_num(r))\n",
    "        df[text_col] = df[text_col].apply(lambda r: trail_ws(r))\n",
    "        df[text_col] = df[text_col].apply(lambda r: remove_stops(r, stopw))\n",
    "        #df[text_col] = df[text_col].apply(lambda r: lemmatize(r))\n",
    "        df[text_col] = df[text_col].apply(lambda r: ' '.join([accent_rem(name) for name in r.split()]))\n",
    "    \n",
    "        # Filter:\n",
    "        df = df[df[text_col] != '']\n",
    "\n",
    "        return(df.reset_index(drop=True))\n",
    "\n",
    "def get_tweets(user, date_ini, date_end, stopw, ecolist):\n",
    "    '''\n",
    "    Function to get tweets from a user given a period range.\n",
    "    params:\n",
    "        - user: twitter user name.\n",
    "        - date_ini: first day of time window to retrieve tweets.\n",
    "        - date_end: last date of time window to retrieve tweets.\n",
    "    '''\n",
    "    # Tweets list:\n",
    "    twts_ls = []\n",
    "\n",
    "    # Twitter scrapper:\n",
    "    for i, tweet in enumerate(sntwitter.TwitterSearchScraper('from:' + user + ' since:' + date_ini + ' until:' + date_end).get_items()):\n",
    "        twts_ls.append([tweet.user.username, tweet.date, tweet.content])\n",
    "        \n",
    "    # Tweets dataframe: \n",
    "    df = pd.DataFrame(twts_ls, columns=['username', 'date', 'text'])\n",
    "    df = treat_text(df, 'text', stopw, ecolist, date_col = 'date', sent_col = None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../../context/SMI/data/utils'\n",
    "stops = ['/db_stopwords_spanish_1.txt', '/db_stopwords_spanish_2.txt']\n",
    "stopw = get_stops(stops, path)\n",
    "ecofile = '/ecofilter.xlsx'\n",
    "ecofiles = [ecofile]\n",
    "eco_filter = get_ecofilter(path, ecofiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Add stop words to database\n",
    "# Add ecolist to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba\n",
    "\n",
    "user = 'dresponsable'\n",
    "date_ini = '2015-10-21'\n",
    "date_end = '2015-10-23'\n",
    "\n",
    "df_tweets = get_tweets(user, date_ini, date_end, stopw, eco_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-22 23:58:14+00:00</td>\n",
       "      <td>reciben semanal rse rsc quieres apuntar puedes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-22 22:08:44+00:00</td>\n",
       "      <td>incita rse comprar diario responsable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-22 18:14:20+00:00</td>\n",
       "      <td>carmen alvarez arenas pp q rse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-22 17:56:34+00:00</td>\n",
       "      <td>directo periscope partidos politicos rse obser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-22 17:48:40+00:00</td>\n",
       "      <td>carmen alvarez arenas rse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-22 17:45:42+00:00</td>\n",
       "      <td>directo periscope partidos politicos rse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-22 17:37:34+00:00</td>\n",
       "      <td>equipo siguiendo propuestas partidos politicos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-22 17:37:05+00:00</td>\n",
       "      <td>vision rse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-22 17:28:34+00:00</td>\n",
       "      <td>vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-22 17:22:58+00:00</td>\n",
       "      <td>llenazo acto observatorio rsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-21 20:31:06+00:00</td>\n",
       "      <td>volkswagen importancia aseguramiento g busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-21 20:16:17+00:00</td>\n",
       "      <td>gustan ls anuncios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-21 20:12:45+00:00</td>\n",
       "      <td>dr lab medicion impactos online empresas venta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-21 19:29:59+00:00</td>\n",
       "      <td>d r lab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-21 18:33:29+00:00</td>\n",
       "      <td>guia x afrontar contribucion empresas ods rse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-21 17:37:21+00:00</td>\n",
       "      <td>otero gracias guapeton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-21 17:25:12+00:00</td>\n",
       "      <td>propuestas ddhh generales justo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-21 04:30:09+00:00</td>\n",
       "      <td>conoce historia condenado repetirla d r lab ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        username                      date  \\\n",
       "0   dresponsable 2015-10-22 23:58:14+00:00   \n",
       "1   dresponsable 2015-10-22 22:08:44+00:00   \n",
       "2   dresponsable 2015-10-22 18:14:20+00:00   \n",
       "3   dresponsable 2015-10-22 17:56:34+00:00   \n",
       "4   dresponsable 2015-10-22 17:48:40+00:00   \n",
       "5   dresponsable 2015-10-22 17:45:42+00:00   \n",
       "6   dresponsable 2015-10-22 17:37:34+00:00   \n",
       "7   dresponsable 2015-10-22 17:37:05+00:00   \n",
       "8   dresponsable 2015-10-22 17:28:34+00:00   \n",
       "9   dresponsable 2015-10-22 17:22:58+00:00   \n",
       "10  dresponsable 2015-10-21 20:31:06+00:00   \n",
       "11  dresponsable 2015-10-21 20:16:17+00:00   \n",
       "12  dresponsable 2015-10-21 20:12:45+00:00   \n",
       "13  dresponsable 2015-10-21 19:29:59+00:00   \n",
       "14  dresponsable 2015-10-21 18:33:29+00:00   \n",
       "15  dresponsable 2015-10-21 17:37:21+00:00   \n",
       "16  dresponsable 2015-10-21 17:25:12+00:00   \n",
       "17  dresponsable 2015-10-21 04:30:09+00:00   \n",
       "\n",
       "                                                 text  \n",
       "0   reciben semanal rse rsc quieres apuntar puedes...  \n",
       "1               incita rse comprar diario responsable  \n",
       "2                      carmen alvarez arenas pp q rse  \n",
       "3   directo periscope partidos politicos rse obser...  \n",
       "4                           carmen alvarez arenas rse  \n",
       "5            directo periscope partidos politicos rse  \n",
       "6   equipo siguiendo propuestas partidos politicos...  \n",
       "7                                          vision rse  \n",
       "8                                              vision  \n",
       "9                       llenazo acto observatorio rsc  \n",
       "10  volkswagen importancia aseguramiento g busines...  \n",
       "11                                 gustan ls anuncios  \n",
       "12  dr lab medicion impactos online empresas venta...  \n",
       "13                                            d r lab  \n",
       "14      guia x afrontar contribucion empresas ods rse  \n",
       "15                             otero gracias guapeton  \n",
       "16                    propuestas ddhh generales justo  \n",
       "17  conoce historia condenado repetirla d r lab ma...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-22 17:56:34+00:00</td>\n",
       "      <td>directo periscope partidos politicos rse obser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-22 17:45:42+00:00</td>\n",
       "      <td>directo periscope partidos politicos rse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-22 17:37:34+00:00</td>\n",
       "      <td>equipo siguiendo propuestas partidos politicos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dresponsable</td>\n",
       "      <td>2015-10-21 18:33:29+00:00</td>\n",
       "      <td>guia x afrontar contribucion empresas ods rse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        username                      date  \\\n",
       "3   dresponsable 2015-10-22 17:56:34+00:00   \n",
       "5   dresponsable 2015-10-22 17:45:42+00:00   \n",
       "6   dresponsable 2015-10-22 17:37:34+00:00   \n",
       "14  dresponsable 2015-10-21 18:33:29+00:00   \n",
       "\n",
       "                                                 text  \n",
       "3   directo periscope partidos politicos rse obser...  \n",
       "5            directo periscope partidos politicos rse  \n",
       "6   equipo siguiendo propuestas partidos politicos...  \n",
       "14      guia x afrontar contribucion empresas ods rse  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ecotweets(df_tweets, eco_filter, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
