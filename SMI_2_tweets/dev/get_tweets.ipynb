{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 00:48:14.787156: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-26 00:48:14.787196: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# importing libraries and packages\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accent_rem(name):\n",
    "    '''\n",
    "    Function to remove accents from an alphanumeric string:\n",
    "    params:\n",
    "        - name: character string.\n",
    "    Output: string without accents.\n",
    "    '''\n",
    "    #Define replacements (possible accents or other special char)\n",
    "    replacements = (\n",
    "        (\"á\", \"a\"),\n",
    "        (\"é\", \"e\"),\n",
    "        (\"í\", \"i\"),\n",
    "        (\"ó\", \"o\"),\n",
    "        (\"ú\", \"u\"),\n",
    "        (\"ñ\", 'n'),\n",
    "        (\"à\", \"a\"),\n",
    "        (\"è\", \"e\"),\n",
    "        (\"ì\", \"i\"),\n",
    "        (\"ò\", \"o\"),\n",
    "        (\"ù\", \"u\"),\n",
    "        (\"ä\", 'a'),\n",
    "        (\"ë\", \"e\"),\n",
    "        (\"ï\", \"i\"),\n",
    "        (\"ö\", \"o\"),\n",
    "        (\"ü\", \"u\"),\n",
    "    )\n",
    "    #Replace with tuple:\n",
    "    for a, b in replacements:\n",
    "        name = name.replace(a, b).replace(a.upper(), b.upper())\n",
    "    return(name)\n",
    "\n",
    "def trail_ws(tweet):\n",
    "    return re.sub(' +', ' ', tweet)\n",
    "\n",
    "def remove_num(tweet):\n",
    "    return ''.join([i for i in tweet if not i.isdigit()])\n",
    "\n",
    "def treat_text(df, text_col, stopw = [], ecolist = [], date_col = 'date', sent_col = 'sentiment'):\n",
    "        '''\n",
    "        Function to treat the corpus columns:\n",
    "        params:\n",
    "            - df: dataframe to treat.\n",
    "        Output: Dataframe treated.\n",
    "        '''\n",
    "        # Sanity checks:\n",
    "        df = df.fillna('')\n",
    "        \n",
    "        # Formatting corpus columns:\n",
    "\n",
    "        if date_col == 'date':\n",
    "            df[date_col] = pd.to_datetime(df[date_col])\n",
    "        if sent_col == 'sentiment':\n",
    "            df[sent_col] = df[sent_col].replace(',', '', regex=True)\n",
    "\n",
    "        #Columns treatment:\n",
    "        df[text_col] = df[text_col].apply(lambda r: ' '.join([accent_rem(name) for name in r.split()]))\n",
    "        df[text_col] = df[text_col].apply(lambda r: ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", r).split()))\n",
    "        df[text_col] = df[text_col].apply(lambda r: r.lower())\n",
    "        df[text_col] = df[text_col].apply(lambda r: remove_num(r))\n",
    "        df[text_col] = df[text_col].apply(lambda r: trail_ws(r))\n",
    "        df[text_col] = df[text_col].apply(lambda r: remove_stops(r, stopw))\n",
    "        #df[text_col] = df[text_col].apply(lambda r: lemmatize(r))\n",
    "        df[text_col] = df[text_col].apply(lambda r: ' '.join([accent_rem(name) for name in r.split()]))\n",
    "    \n",
    "        # Filter:\n",
    "        df = df[df[text_col] != '']\n",
    "\n",
    "        return(df.reset_index(drop=True))\n",
    "\n",
    "def get_tweets(user, date_ini, date_end, stopw, ecolist):\n",
    "    '''\n",
    "    Function to get tweets from a user given a period range.\n",
    "    params:\n",
    "        - user: twitter user name.\n",
    "        - date_ini: first day of time window to retrieve tweets.\n",
    "        - date_end: last date of time window to retrieve tweets.\n",
    "    '''\n",
    "    # Tweets list:\n",
    "    twts_ls = []\n",
    "\n",
    "    # Twitter scrapper:\n",
    "    for i, tweet in enumerate(sntwitter.TwitterSearchScraper('from:' + user + ' since:' + date_ini + ' until:' + date_end).get_items()):\n",
    "        twts_ls.append([tweet.user.username, tweet.date, tweet.content])\n",
    "        \n",
    "    # Tweets dataframe: \n",
    "    df = pd.DataFrame(twts_ls, columns=['username', 'date', 'text'])\n",
    "    df = treat_text(df, 'text', stopw, ecolist, date_col = 'date', sent_col = None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../../context/SMI/data/utils'\n",
    "stops = ['/db_stopwords_spanish_1.txt', '/db_stopwords_spanish_2.txt']\n",
    "stopw = get_stops(stops, path)\n",
    "ecofile = '/ecofilter.xlsx'\n",
    "ecofiles = [ecofile]\n",
    "eco_filter = get_ecofilter(path, ecofiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Add stop words to database\n",
    "# Add ecolist to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba\n",
    "\n",
    "user = 'Tallerator'\n",
    "date_ini = '2015-10-21'\n",
    "date_end = '2015-10-23'\n",
    "\n",
    "df_tweets = get_tweets(user, date_ini, date_end, stopw, eco_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-22 12:53:09+00:00</td>\n",
       "      <td>hora volkswagen investiga motor incorporar sof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-22 12:35:33+00:00</td>\n",
       "      <td>insolito autocaravana hecha piezas lego funcio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-22 09:23:43+00:00</td>\n",
       "      <td>volkswagen detiene venta europa coches motor e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-22 09:15:11+00:00</td>\n",
       "      <td>curioso superb black crystal colaboracion prec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-22 08:05:04+00:00</td>\n",
       "      <td>vwgate volkswagen utilizo motores trucados ama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-22 08:03:57+00:00</td>\n",
       "      <td>delorean dmc historia coche regresoalfuturo os...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 21:46:54+00:00</td>\n",
       "      <td>ultimahora vwgate volkswagen utilizo motores t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 19:56:35+00:00</td>\n",
       "      <td>noches manana motor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 15:28:33+00:00</td>\n",
       "      <td>delorean dmc historia coche regresoalfuturo os...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 14:20:24+00:00</td>\n",
       "      <td>lanza espana gti motor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 11:55:08+00:00</td>\n",
       "      <td>ojo refuerza semana control carreteras secunda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 11:32:16+00:00</td>\n",
       "      <td>curioso superb black crystal colaboracion prec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 10:16:48+00:00</td>\n",
       "      <td>sabias coche regresoalfuturo etico contamos an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 10:04:31+00:00</td>\n",
       "      <td>comienza produccion m coupe leipzig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 09:25:01+00:00</td>\n",
       "      <td>delorean dmc historia coche regresoalfuturo os...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 08:35:08+00:00</td>\n",
       "      <td>coches x mundo volkswagen lavida china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 08:02:02+00:00</td>\n",
       "      <td>peques coche consejos seguridad os contamos gt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 07:38:03+00:00</td>\n",
       "      <td>cifra ventas coches usados aumentan meses ano ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 07:35:04+00:00</td>\n",
       "      <td>cazados bmw x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      username                      date  \\\n",
       "0   Tallerator 2015-10-22 12:53:09+00:00   \n",
       "1   Tallerator 2015-10-22 12:35:33+00:00   \n",
       "2   Tallerator 2015-10-22 09:23:43+00:00   \n",
       "3   Tallerator 2015-10-22 09:15:11+00:00   \n",
       "4   Tallerator 2015-10-22 08:05:04+00:00   \n",
       "5   Tallerator 2015-10-22 08:03:57+00:00   \n",
       "6   Tallerator 2015-10-21 21:46:54+00:00   \n",
       "7   Tallerator 2015-10-21 19:56:35+00:00   \n",
       "8   Tallerator 2015-10-21 15:28:33+00:00   \n",
       "9   Tallerator 2015-10-21 14:20:24+00:00   \n",
       "10  Tallerator 2015-10-21 11:55:08+00:00   \n",
       "11  Tallerator 2015-10-21 11:32:16+00:00   \n",
       "12  Tallerator 2015-10-21 10:16:48+00:00   \n",
       "13  Tallerator 2015-10-21 10:04:31+00:00   \n",
       "14  Tallerator 2015-10-21 09:25:01+00:00   \n",
       "15  Tallerator 2015-10-21 08:35:08+00:00   \n",
       "16  Tallerator 2015-10-21 08:02:02+00:00   \n",
       "17  Tallerator 2015-10-21 07:38:03+00:00   \n",
       "18  Tallerator 2015-10-21 07:35:04+00:00   \n",
       "\n",
       "                                                 text  \n",
       "0   hora volkswagen investiga motor incorporar sof...  \n",
       "1   insolito autocaravana hecha piezas lego funcio...  \n",
       "2   volkswagen detiene venta europa coches motor e...  \n",
       "3   curioso superb black crystal colaboracion prec...  \n",
       "4   vwgate volkswagen utilizo motores trucados ama...  \n",
       "5   delorean dmc historia coche regresoalfuturo os...  \n",
       "6   ultimahora vwgate volkswagen utilizo motores t...  \n",
       "7                                 noches manana motor  \n",
       "8   delorean dmc historia coche regresoalfuturo os...  \n",
       "9                              lanza espana gti motor  \n",
       "10  ojo refuerza semana control carreteras secunda...  \n",
       "11  curioso superb black crystal colaboracion prec...  \n",
       "12  sabias coche regresoalfuturo etico contamos an...  \n",
       "13                comienza produccion m coupe leipzig  \n",
       "14  delorean dmc historia coche regresoalfuturo os...  \n",
       "15             coches x mundo volkswagen lavida china  \n",
       "16     peques coche consejos seguridad os contamos gt  \n",
       "17  cifra ventas coches usados aumentan meses ano ...  \n",
       "18                                      cazados bmw x  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [username, date, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ecotweets(df_tweets, eco_filter, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = 'inversion publicitaria atresmedia recorta cuota publicitaria mediaset http prnoticias com marketing inversion publicitaria atresmedia mediaset duopolio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mediaset com http duopolio cuota recorta atresmedia marketing inversion publicitaria prnoticias'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(list(set(prueba.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['text'] = df_tweets['text'].apply(lambda r: ' '.join(list(set(r.split()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'revestidas cristales colaboracion llantas pequenos crystal black preciosa curioso superb'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(list(set(df_tweets.iloc[3,2].split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba.split('AGREEMENT')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-22 12:53:09+00:00</td>\n",
       "      <td>motor incorporar volkswagen manipulaba hora in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-22 12:35:33+00:00</td>\n",
       "      <td>lego contamos gt piezas funciona hecha os auto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-22 09:23:43+00:00</td>\n",
       "      <td>motor via europa ea volkswagen eu coches detie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-22 09:15:11+00:00</td>\n",
       "      <td>revestidas cristales colaboracion llantas pequ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-22 08:05:04+00:00</td>\n",
       "      <td>producido argentina amarok motores volkswagen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-22 08:03:57+00:00</td>\n",
       "      <td>dmc contamos coche gt and historia os regresoa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 21:46:54+00:00</td>\n",
       "      <td>producido argentina amarok motores volkswagen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 19:56:35+00:00</td>\n",
       "      <td>noches manana motor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 15:28:33+00:00</td>\n",
       "      <td>dmc contamos coche gt and historia os regresoa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 14:20:24+00:00</td>\n",
       "      <td>lanza motor espana gti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 11:55:08+00:00</td>\n",
       "      <td>carreteras seguridadvial ojo trafico secundari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 11:32:16+00:00</td>\n",
       "      <td>revestidas cristales colaboracion llantas pequ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 10:16:48+00:00</td>\n",
       "      <td>etico contamos coche and sabias regresoalfutur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 10:04:31+00:00</td>\n",
       "      <td>leipzig comienza produccion m coupe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 09:25:01+00:00</td>\n",
       "      <td>dmc contamos coche gt and historia os regresoa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 08:35:08+00:00</td>\n",
       "      <td>china x volkswagen mundo coches lavida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 08:02:02+00:00</td>\n",
       "      <td>contamos coche gt seguridad os peques consejos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 07:38:03+00:00</td>\n",
       "      <td>cifra com meses coches ventas aumentan ejercic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tallerator</td>\n",
       "      <td>2015-10-21 07:35:04+00:00</td>\n",
       "      <td>bmw x cazados</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      username                      date  \\\n",
       "0   Tallerator 2015-10-22 12:53:09+00:00   \n",
       "1   Tallerator 2015-10-22 12:35:33+00:00   \n",
       "2   Tallerator 2015-10-22 09:23:43+00:00   \n",
       "3   Tallerator 2015-10-22 09:15:11+00:00   \n",
       "4   Tallerator 2015-10-22 08:05:04+00:00   \n",
       "5   Tallerator 2015-10-22 08:03:57+00:00   \n",
       "6   Tallerator 2015-10-21 21:46:54+00:00   \n",
       "7   Tallerator 2015-10-21 19:56:35+00:00   \n",
       "8   Tallerator 2015-10-21 15:28:33+00:00   \n",
       "9   Tallerator 2015-10-21 14:20:24+00:00   \n",
       "10  Tallerator 2015-10-21 11:55:08+00:00   \n",
       "11  Tallerator 2015-10-21 11:32:16+00:00   \n",
       "12  Tallerator 2015-10-21 10:16:48+00:00   \n",
       "13  Tallerator 2015-10-21 10:04:31+00:00   \n",
       "14  Tallerator 2015-10-21 09:25:01+00:00   \n",
       "15  Tallerator 2015-10-21 08:35:08+00:00   \n",
       "16  Tallerator 2015-10-21 08:02:02+00:00   \n",
       "17  Tallerator 2015-10-21 07:38:03+00:00   \n",
       "18  Tallerator 2015-10-21 07:35:04+00:00   \n",
       "\n",
       "                                                 text  \n",
       "0   motor incorporar volkswagen manipulaba hora in...  \n",
       "1   lego contamos gt piezas funciona hecha os auto...  \n",
       "2   motor via europa ea volkswagen eu coches detie...  \n",
       "3   revestidas cristales colaboracion llantas pequ...  \n",
       "4   producido argentina amarok motores volkswagen ...  \n",
       "5   dmc contamos coche gt and historia os regresoa...  \n",
       "6   producido argentina amarok motores volkswagen ...  \n",
       "7                                 noches manana motor  \n",
       "8   dmc contamos coche gt and historia os regresoa...  \n",
       "9                              lanza motor espana gti  \n",
       "10  carreteras seguridadvial ojo trafico secundari...  \n",
       "11  revestidas cristales colaboracion llantas pequ...  \n",
       "12  etico contamos coche and sabias regresoalfutur...  \n",
       "13                leipzig comienza produccion m coupe  \n",
       "14  dmc contamos coche gt and historia os regresoa...  \n",
       "15             china x volkswagen mundo coches lavida  \n",
       "16     contamos coche gt seguridad os peques consejos  \n",
       "17  cifra com meses coches ventas aumentan ejercic...  \n",
       "18                                      bmw x cazados  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = 'consu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['consumo',\n",
       " 'consumir',\n",
       " 'consumido',\n",
       " 'consume',\n",
       " 'constanza',\n",
       " 'pepe',\n",
       " 'arbol',\n",
       " 'd',\n",
       " 'd']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'consumo consumir consumido consume constanza pepe arbol d d'\n",
    "test.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check ecolist OK:\n",
    "\n",
    "' '.join([word for word in test.split() if word in prueba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba = 'h'\n",
    "len(prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['consumo', 'consumir', 'consumido', 'consume', 'constanza', 'pepe', 'arbol']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in test.split() if len(word) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringliteral = 'hola mi web es https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hola mi web es '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'http\\S+', '', stringliteral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En vigor un nou procediment d’inscripció de naixements i defuncions., i sobre documentació Consulta les novetats http:// bit.ly/1VTv9iA'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = df_prueba['text'][2]\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stops(stops, path):\n",
    "    \n",
    "    with open(path + stops[0]) as f:\n",
    "        stopw_1 = f.read().splitlines()\n",
    "    with open(path + stops[1]) as f:\n",
    "        stopw_2 = f.read().splitlines()\n",
    "\n",
    "    stopw_1[0] = stopw_1[0].replace('\\ufeff', '')\n",
    "    stopw = stopw_1 + stopw_2\n",
    "    stopw = [accent_rem(word) for word in stopw]\n",
    "    return(stopw)\n",
    "\n",
    "def get_ecofilter(path, files):\n",
    "    '''\n",
    "    Function to get the list of words to filter the tweets\n",
    "    '''\n",
    "    eco_filter = pd.DataFrame()\n",
    "    for file in files:\n",
    "        eco_filter = pd.concat([eco_filter, pd.read_excel(path + file, header=None)], axis=0)\n",
    "    eco_filter.drop_duplicates(inplace=True)\n",
    "    eco_filter = eco_filter.iloc[:,0].to_list()\n",
    "    #eco_filter = [lemmatize(word) for word in eco_filter]\n",
    "    return [accent_rem(word) for word in eco_filter]\n",
    "\n",
    "def accent_rem(name):\n",
    "    '''\n",
    "    Function to remove accents from an alphanumeric string:\n",
    "    params:\n",
    "        - name: character string.\n",
    "    Output: string without accents.\n",
    "    '''\n",
    "    #Define replacements (possible accents or other special char)\n",
    "    replacements = (\n",
    "        (\"á\", \"a\"),\n",
    "        (\"é\", \"e\"),\n",
    "        (\"í\", \"i\"),\n",
    "        (\"ó\", \"o\"),\n",
    "        (\"ú\", \"u\"),\n",
    "        (\"ñ\", 'n'),\n",
    "        (\"à\", \"a\"),\n",
    "        (\"è\", \"e\"),\n",
    "        (\"ì\", \"i\"),\n",
    "        (\"ò\", \"o\"),\n",
    "        (\"ù\", \"u\"),\n",
    "        (\"ä\", 'a'),\n",
    "        (\"ë\", \"e\"),\n",
    "        (\"ï\", \"i\"),\n",
    "        (\"ö\", \"o\"),\n",
    "        (\"ü\", \"u\"),\n",
    "    )\n",
    "    #Replace with tuple:\n",
    "    for a, b in replacements:\n",
    "        name = name.replace(a, b).replace(a.upper(), b.upper())\n",
    "    return(name)\n",
    "\n",
    "def tweet_cleaner(tweet, stopw, ecol):\n",
    "    '''\n",
    "    Function to treat the text of a tweet.\n",
    "    params:\n",
    "        - tweet: the document itself.\n",
    "    output: the tweet cleaned.\n",
    "    '''\n",
    "    # Remove urls (http in advance)\n",
    "    tweet = re.sub(r'http.*',\"\", tweet)\n",
    "    tweet = re.sub(r'pic.twitter\\S+', '', tweet)\n",
    "    # Remove mentions and hastags.\n",
    "    tweet = re.sub(r'#\\S+', '', tweet)\n",
    "    tweet = re.sub(r'@\\S+', '', tweet)\n",
    "    # Remove spanish vowel accents.\n",
    "    tweet = ' '.join([accent_rem(word) for word in tweet.split()])\n",
    "    # Remove special characters.\n",
    "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \", tweet).split())\n",
    "    # Lower captions.\n",
    "    tweet = tweet.lower()\n",
    "    # Remove numbers.\n",
    "    tweet = ''.join([i for i in tweet if not i.isdigit()])\n",
    "    # Remove white spaces.\n",
    "    tweet = re.sub(' +', ' ', tweet)\n",
    "    # Remove stopwords.\n",
    "    tweet = ' '.join([word for word in tweet.split() if not word in stopw])\n",
    "    # Filter words length (<1 and >15).\n",
    "    tweet = ' '.join([word for word in tweet.split() if len(word) > 1 and len(word) <= 15])\n",
    "    # Filter ecolist.\n",
    "    commons = [word for word in ecol if word in tweet]\n",
    "    if len(commons) < 1:\n",
    "        tweet = ''\n",
    "    #if len(tweet) > 1:\n",
    "        #Lemmatize:\n",
    "        #tweet = ' '.join([tok.lemma_.lower() for tok in nlp(tweet)])\n",
    "    return tweet\n",
    "\n",
    "def treat_text(df, stopw, ecol):\n",
    "    '''\n",
    "    Function to treat the tweets of a dataframe:\n",
    "    params:\n",
    "        - df: dataframe with tweets.\n",
    "    output: \n",
    "    '''\n",
    "    df['text'] = df['text'].fillna(' ')\n",
    "    df['text'] = df['text'].apply(lambda r: tweet_cleaner(r, stopw, ecol))\n",
    "    df = df[df['text'] != '']\n",
    "    df = df[['username', 'date', 'text']]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../../context/SMI/data/utils'\n",
    "stops = ['/db_stopwords_spanish_1.txt', '/db_stopwords_spanish_2.txt']\n",
    "stopw = get_stops(stops, path)\n",
    "ecofile = '/ecofilter.xlsx'\n",
    "ecofiles = [ecofile]\n",
    "eco_filter = get_ecofilter(path, ecofiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../../context/SMI/data/get_tweets/2015/DF_2015_10_22.json'\n",
    "with open(path) as f:\n",
    "    data = json.load(f)\n",
    "df_prueba = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prueba_t = treat_text(df_prueba, stopw, eco_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMBarcelona</td>\n",
       "      <td>2015-10-22 14:00:00</td>\n",
       "      <td>setmana parlarem economia social amb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COMBarcelona</td>\n",
       "      <td>2015-10-22 09:10:00</td>\n",
       "      <td>forum inversio healthcare social empreses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EqOVER</td>\n",
       "      <td>2015-10-23 00:56:00</td>\n",
       "      <td>buscar maneras mostrar vision mision empresa m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xaviicastro_</td>\n",
       "      <td>2015-10-22 22:34:00</td>\n",
       "      <td>manda orgullo reina desgracia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xaviicastro_</td>\n",
       "      <td>2015-10-22 22:20:00</td>\n",
       "      <td>mercedes cambiate pareces abestruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86532</th>\n",
       "      <td>OnasisZarate</td>\n",
       "      <td>2015-10-23 01:45:00</td>\n",
       "      <td>encuentro reunion dirigentes prd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86533</th>\n",
       "      <td>OnasisZarate</td>\n",
       "      <td>2015-10-23 00:28:00</td>\n",
       "      <td>quiero felicitar amiga nombramiento presidenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86534</th>\n",
       "      <td>OnasisZarate</td>\n",
       "      <td>2015-10-22 15:56:00</td>\n",
       "      <td>amiga felicidades tu cumpleanos gracias tu ami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86535</th>\n",
       "      <td>OnasisZarate</td>\n",
       "      <td>2015-10-22 04:44:00</td>\n",
       "      <td>lideres izquierda pic twitter com kyyfwhpwv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86536</th>\n",
       "      <td>OnasisZarate</td>\n",
       "      <td>2015-10-22 04:29:00</td>\n",
       "      <td>encuentro reunion mis amigos asociacion chueco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86537 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           username                 date  \\\n",
       "0      COMBarcelona  2015-10-22 14:00:00   \n",
       "1      COMBarcelona  2015-10-22 09:10:00   \n",
       "2            EqOVER  2015-10-23 00:56:00   \n",
       "3      Xaviicastro_  2015-10-22 22:34:00   \n",
       "4      Xaviicastro_  2015-10-22 22:20:00   \n",
       "...             ...                  ...   \n",
       "86532  OnasisZarate  2015-10-23 01:45:00   \n",
       "86533  OnasisZarate  2015-10-23 00:28:00   \n",
       "86534  OnasisZarate  2015-10-22 15:56:00   \n",
       "86535  OnasisZarate  2015-10-22 04:44:00   \n",
       "86536  OnasisZarate  2015-10-22 04:29:00   \n",
       "\n",
       "                                                    text  \n",
       "0                   setmana parlarem economia social amb  \n",
       "1              forum inversio healthcare social empreses  \n",
       "2      buscar maneras mostrar vision mision empresa m...  \n",
       "3                          manda orgullo reina desgracia  \n",
       "4                     mercedes cambiate pareces abestruz  \n",
       "...                                                  ...  \n",
       "86532                   encuentro reunion dirigentes prd  \n",
       "86533  quiero felicitar amiga nombramiento presidenta...  \n",
       "86534  amiga felicidades tu cumpleanos gracias tu ami...  \n",
       "86535        lideres izquierda pic twitter com kyyfwhpwv  \n",
       "86536  encuentro reunion mis amigos asociacion chueco...  \n",
       "\n",
       "[86537 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prueba_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
