{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "from io import StringIO\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get db config\n",
    "with open('../../../../context/SMI/config/postgres.config') as config_file:\n",
    "    db_config = json.load(config_file)\n",
    "\n",
    "# Local database deployment\n",
    "conn = psycopg2.connect(\n",
    "                        dbname=db_config['db_name'],\n",
    "                        user=db_config['db_user'],\n",
    "                        host='localhost',\n",
    "                        port=db_config['db_port'],\n",
    "                        password=db_config['db_password'],\n",
    "                        options=db_config['db_options']\n",
    "                        )\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "schema = db_config['db_schema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories:\n",
    "if not os.path.isdir(logs_path):\n",
    "    print('Environment job: Creating ' + app_name + ' logs directory')\n",
    "    os.makedirs(logs_path)\n",
    "\n",
    "if not os.path.isdir(temp_data_path):\n",
    "    print('Environment job: Creating ' + app_name + ' data directory')\n",
    "    os.makedirs(temp_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment job: Checking folder logs/\n",
      "Environment job: Folder logs/ exists\n",
      "Environment job: Checking folder ../data/\n",
      "Environment job: Folder ../data/ exists\n"
     ]
    }
   ],
   "source": [
    "# Directories check:\n",
    "print('Environment job: Checking folder '+ logs_path)\n",
    "if os.path.isdir(logs_path):\n",
    "    print('Environment job: Folder '+ logs_path + ' exists')\n",
    "else:\n",
    "    print('Environment job: Folder '+ logs_path + ' does not exists')\n",
    "    print('Environment job: Creating folder '+ logs_path)\n",
    "    os.makedirs(logs_path)\n",
    "\n",
    "print('Environment job: Checking folder '+ temp_data_path)\n",
    "if os.path.isdir(temp_data_path):\n",
    "    print('Environment job: Folder '+ temp_data_path + ' exists')\n",
    "else:\n",
    "    print('Environment job: Folder '+ temp_data_path + ' does not exists')\n",
    "    print('Environment job: Creating folder '+ temp_data_path)\n",
    "    os.makedirs(temp_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseCreation:\n",
    "    '''\n",
    "    Database creation and initial data insertion:\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                queries_path,\n",
    "                conn,\n",
    "                schema\n",
    "                ):\n",
    "        self.queries_path = queries_path\n",
    "        self.conn = conn\n",
    "        self.cur = cur\n",
    "        self.schema = schema\n",
    "\n",
    "    @staticmethod\n",
    "    def get_info(url, header):\n",
    "        '''\n",
    "        Function to get the initial twitter users file.\n",
    "        Params: \n",
    "            - url: list of url pages with the most followed spanish twitter accounts.\n",
    "            - header: specifies robots.txt user agent.\n",
    "        Output: Uncleaned dataframe with parsed tables.\n",
    "        '''\n",
    "        try:\n",
    "\n",
    "            #Get text from url:\n",
    "            page = requests.get(url, headers=header)\n",
    "            soup = BeautifulSoup(page.text, \"lxml\")\n",
    "            results = soup.find(id=\"listado\")\n",
    "\n",
    "            #Get table from text:\n",
    "            df = pd.DataFrame([[tr for tr in tab] for tab in results.table])\n",
    "            df = df.loc[:,1:]\n",
    "\n",
    "            #Get column names:\n",
    "            colnames = [str(name) for name in df.iloc[0]]\n",
    "            colnames = [re.search('<b>(.*)</b>', name).group(1).replace('<br/>', ' ') for name in colnames if name != 'None']\n",
    "            df = df.loc[1:,2:]\n",
    "            df.columns = colnames\n",
    "\n",
    "            #Dropping columns:\n",
    "            df = df[~df['Twittero'].isnull()].reset_index(drop=True)\n",
    "            return(df)\n",
    "\n",
    "        except:\n",
    "            print('Get info from XML files error')\n",
    "            return 1\n",
    "\n",
    "    @staticmethod\n",
    "    def get_user(input):\n",
    "        '''\n",
    "        Function to extract user name from the list.\n",
    "        Params:\n",
    "            - input: Twitter message.\n",
    "        Output: Twitter user.\n",
    "        '''\n",
    "        try:\n",
    "            #Locating the username:\n",
    "            s = str(input)\n",
    "            start = s.find(\">@\") + len(\">@\")\n",
    "            end = s.find(\"<br/\")\n",
    "            substring = s[start:end]\n",
    "\n",
    "            #Returning the username from:\n",
    "            return(substring)\n",
    "\n",
    "        except:\n",
    "            print('Get username from XML format error')\n",
    "            return 1\n",
    "\n",
    "    @staticmethod\n",
    "    def get_n(input):\n",
    "        '''\n",
    "        Function to extract numeric values from the table:\n",
    "        Params:\n",
    "            - input: Different values from twitter users accounts.\n",
    "        Output: Value\n",
    "        '''\n",
    "        try:\n",
    "            #Locating the value;\n",
    "            s = str(input)\n",
    "            start = s.find(\">\") + len(\">\")\n",
    "            end = s.find(\"</td\")\n",
    "            substring = s[start:end]\n",
    "\n",
    "            #Returning the value:\n",
    "            return(substring.replace(',', ''))\n",
    "\n",
    "        except:\n",
    "            print('Get numeric variables from XML format error')\n",
    "            return 1\n",
    "\n",
    "    def get_initial_users_table(self, urls, headers):\n",
    "        '''\n",
    "        Function to create the initial users dataframe.\n",
    "        Params:\n",
    "            - url: list of url pages with the most followed spanish twitter accounts.\n",
    "            - header: specifies robots.txt user agent.\n",
    "        Output: Dataframe with cleaned data.\n",
    "        '''\n",
    "        try:\n",
    "            #Scrap info from wp:\n",
    "            info = self.get_info(urls, headers)\n",
    "\n",
    "            #Columns to clean:\n",
    "            cols = ['Twittero', 'Seguido por', 'Sigue a', 'Tweets', 'Twitea desde', 'Ultimo Tweet', 'Categoria']\n",
    "\n",
    "            #Clean columns:\n",
    "            for col in cols:\n",
    "                if col == 'Twittero':\n",
    "                    users = [self.get_user(info[col][i]) for i in range(info.shape[0])]\n",
    "                    info[col] = users\n",
    "                else:\n",
    "                    info[col] = [self.get_n(info[col][i]) for i in range(info.shape[0])]\n",
    "            return(info)\n",
    "\n",
    "        except:\n",
    "            print('Get initial users table')\n",
    "            return 1\n",
    "\n",
    "    def get_tw_users_list(self, urls, headers, ini_users_dict):\n",
    "        '''\n",
    "        Function to get all users from different urls\n",
    "        Params:\n",
    "            - url: list of url pages with the most followed spanish twitter accounts.\n",
    "            - header: specifies robots.txt user agent.\n",
    "        Output: Users list and users table\n",
    "        '''\n",
    "        #Get all users from tables of different sections:\n",
    "        try:\n",
    "            users = []\n",
    "            df_out = pd.DataFrame()\n",
    "            for i in range(len(urls)):\n",
    "                \n",
    "                #Create users dataframe and users list:\n",
    "                df = self.get_initial_users_table(urls[i][0], headers)\n",
    "                df_out = pd.concat([df_out, df], axis=0).reset_index(drop=True)\n",
    "                users.extend(df['Twittero'].to_list())\n",
    "\n",
    "            #Drop duplicates:\n",
    "            if len(users) != len(set(users)):\n",
    "                users = list(set(users))\n",
    "                df_out = df_out.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "            #Formating columns:\n",
    "            df_out.columns = [key for key in list(ini_users_dict.keys())]\n",
    "            df_out = df_out.astype(ini_users_dict)\n",
    "            df_out['lastTweet'] = np.where(df_out['lastTweet']=='n/d', df_out['tweetsSince'], df_out['lastTweet'])\n",
    "            df_out['tweetsSince']=pd.to_datetime(df_out['tweetsSince'])\n",
    "            df_out['lastTweet']=pd.to_datetime(df_out['lastTweet'])\n",
    "            df_out = df_out.fillna(0)\n",
    "            return(df_out)\n",
    "\n",
    "        except:\n",
    "            print('Get twitter users list error')\n",
    "            return 1\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_usrs_loc(df, munlist):\n",
    "        '''\n",
    "        Function to filter the location field given a municipalities list, to ensure spanish users:\n",
    "        params:\n",
    "            - df: input dataframe with users information:\n",
    "            - munlist: list of municipalities:\n",
    "        Output: filtered users table.\n",
    "        '''\n",
    "        #Convert location field to lower case:\n",
    "        df['location'] = df['location'].apply(lambda r: r.replace(',', ''))\n",
    "        df['location'] = df['location'].apply(lambda r: r.lower())\n",
    "\n",
    "        #Filter location:\n",
    "        df = df[df['location'].isin(munlist)]\n",
    "        \n",
    "        return(df)\n",
    "\n",
    "    def backup_check(self, path, db_munlist, kind):\n",
    "        '''\n",
    "        Function to check whether there are backups.\n",
    "        params:\n",
    "            - path: relative path to the backup file.\n",
    "            - kind: initial users or users.\n",
    "        Output: \n",
    "            - df: users dataframe.\n",
    "            - usr_ls: list of screenName users.\n",
    "            - check: boolean to check whether there are backup or not.\n",
    "        '''\n",
    "        print('Data job: Check if ' + kind + ' backup exists.')\n",
    "        if os.path.isfile(path):\n",
    "\n",
    "            print('Data job: ' + kind + ' backup exists. Loading file: ' + path)\n",
    "            with open(path, 'r') as f:\n",
    "\n",
    "                df = pd.json_normalize(json.load(f))\n",
    "                if kind == 'users':\n",
    "                    print('Data Engineering job: Filtering location from backup users.')\n",
    "                    print('Data Engineering job: Observations before filter: ' + str(df.shape[0]))\n",
    "                    df = self.filter_usrs_loc(df, db_munlist)\n",
    "                    df['ff_lookup'] = False\n",
    "                    print('Data Engineering job: Observations after filter: ' + str(df.shape[0]))\n",
    "                usr_ls = df['screenName'].to_list()\n",
    "                check = True\n",
    "                print('Data job: ' + kind + ' backup from json file retrieved.')\n",
    "        else:\n",
    "\n",
    "            print('Data job: ' + kind + ' backup does not exists. ')\n",
    "            df = pd.DataFrame()\n",
    "            usr_ls = []\n",
    "            check = False\n",
    "        \n",
    "        return(df, usr_ls, check)\n",
    "\n",
    "    @staticmethod\n",
    "    def fetchone_SQL(path):\n",
    "        \"\"\"\n",
    "        Function to fetch one observation from a query to database:\n",
    "        params:\n",
    "            - path: relative path to the file.\n",
    "        \"\"\"\n",
    "        with open(path, 'r') as f:\n",
    "            query = f.read().format(schema=schema)\n",
    "            try:\n",
    "                cur.execute(query)\n",
    "                return(cur.fetchone()[0])\n",
    "            except (Exception, psycopg2.DatabaseError) as error:\n",
    "                conn.rollback()\n",
    "                cur.close()\n",
    "                print(error) \n",
    "    \n",
    "    @staticmethod\n",
    "    def fetchall_SQL(path):\n",
    "        \"\"\"\n",
    "        Function to fetch all observations from a query to databasee:\n",
    "        params:\n",
    "            - path: relative path to the file.\n",
    "        \"\"\"\n",
    "        with open(path, 'r') as f: \n",
    "            query = f.read().format(schema=schema)\n",
    "            try:\n",
    "                cur.execute(query)\n",
    "                db_fetch = cur.fetchall()\n",
    "                db_fetch = [db_fetch[i][0] for i in range(len(db_fetch))]\n",
    "                return(db_fetch)\n",
    "            except (Exception, psycopg2.DatabaseError) as error:\n",
    "                conn.rollback()\n",
    "                cur.close()\n",
    "                print(error)\n",
    "\n",
    "    @staticmethod\n",
    "    def query_SQL(path):\n",
    "        \"\"\"\n",
    "        Function to make a query to database:\n",
    "        params:\n",
    "            - path: relative path to the file.\n",
    "        \"\"\"\n",
    "        with open(path, 'r') as f:\n",
    "            query = f.read().format(schema=schema)\n",
    "            try:\n",
    "                cur.execute(query)\n",
    "            except (Exception, psycopg2.DatabaseError) as error:\n",
    "                conn.rollback()\n",
    "                cur.close()\n",
    "                print(error)\n",
    "\n",
    "    @staticmethod\n",
    "    def df_to_postgres(conn, df, table):\n",
    "        \"\"\"\n",
    "        Function to save dataframe into postgres with copy_from:\n",
    "        params:\n",
    "            - conn: database connection.\n",
    "            - df: pandas dataframe.\n",
    "            - table: database table.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            #Buffering the dataframe into memory:\n",
    "            buffer = StringIO()\n",
    "            df.to_csv(buffer, header=False, index=False)\n",
    "            buffer.seek(0)\n",
    "\n",
    "            #Copy cached dataframe into postgres:\n",
    "            cur = conn.cursor()\n",
    "            cur.copy_from(buffer, table, sep=\",\")\n",
    "            conn.commit()\n",
    "            \n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            conn.rollback()\n",
    "            cur.close()\n",
    "            print(error)\n",
    "            return 1\n",
    "        cur.close()\n",
    "\n",
    "    def db_cs(self):\n",
    "        '''\n",
    "        Function to check and create the database schema and tables.\n",
    "        params: selft referenced, no params.\n",
    "        '''\n",
    "        # Check if the schema exists.\n",
    "        print('Database job: Check if SMI schema exists.')\n",
    "        schema_check = self.fetchone_SQL(queries_path + 'SMI_schema_check.sql')\n",
    "\n",
    "        # If schema exist, check tables.\n",
    "        if schema_check:\n",
    "\n",
    "            # Check initial users table.\n",
    "            print('Database job: SMI schema exists on DB.')\n",
    "            print('Database job: Check if initial users table exist on DB.')\n",
    "            db_ini_check = self.fetchone_SQL(queries_path + 'SMI_ini_users_check.sql')\n",
    "\n",
    "            # If exists, do nothing.\n",
    "            if db_ini_check:\n",
    "                print('Database job: Initial users table exist on DB.')\n",
    "\n",
    "            # If it does not exist, create initial users table.\n",
    "            else:\n",
    "                print('Database job: Initial users table does not exist on DB.')\n",
    "                print('Database job: Creating initial users table on DB.')\n",
    "                self.query_SQL(queries_path + 'SMI_ini_users_table_creation.sql')\n",
    "                print('Database job: Initial users table created on DB.')\n",
    "\n",
    "            # Check users table.\n",
    "            print('Database job: Check if users table exist on DB.')\n",
    "            db_usr_check = self.fetchone_SQL(queries_path + 'SMI_usrs_table_check.sql')\n",
    "\n",
    "            #If exists, do nothing.\n",
    "            if db_usr_check:\n",
    "                print('Database job: Users table exist on DB.')\n",
    "\n",
    "            #If it does not exist, create users table.\n",
    "            else:\n",
    "                print('Database job: Users table does not exist on DB.')\n",
    "                print('Database job: Creating users table on DB.')\n",
    "                self.query_SQL(queries_path + 'SMI_usrs_table_creation.sql')\n",
    "                print('Database job: Users table created on DB.')\n",
    "\n",
    "        # If schema does not exists, create schema and tables.\n",
    "        else:\n",
    "            print('Database job: SMI schema does not exist.')\n",
    "            print('Database job: Cold start - Creating SMI schema and tables on DB.')\n",
    "            self.query_SQL(queries_path + 'SMI_coldstart_database.sql')\n",
    "            print('Database job: DB schema and tables created.')\n",
    "\n",
    "    def scrap_users(self):\n",
    "        '''\n",
    "        Function to scrap initial users from url:\n",
    "        params: self referenced, no params.\n",
    "        '''\n",
    "        # Scrap ini users, create backup and fill database table:\n",
    "        print('Scraping job: Retrieve initial users from url.')\n",
    "        df = self.get_tw_users_list(urls, headers, ini_users_dict)\n",
    "        print('Scraping job: Initial users from url retrieved.')\n",
    "        print('Scraping job: Save initial users to json backup.')\n",
    "        df.to_json(temp_data_path + 'db_ini_users_' + db_today + '.json', orient='records', date_format='iso')\n",
    "        self.df_to_postgres(conn, df, initial_users_table)\n",
    "        print('Database job: Initial users table created on DB.')\n",
    "\n",
    "    def insert_ini_users(self):\n",
    "        '''\n",
    "        Function to insert initial users into DB.\n",
    "        params: self referenced, no params.\n",
    "        '''\n",
    "        db_ini_ls = self.fetchall_SQL(queries_path + 'SMI_ini_database_screenName.sql')\n",
    "        path_ini = temp_data_path + 'db_ini_users_' + db_ini_users_bkp + '.json'\n",
    "        df_ini_users, df_ini_ls, df_ini_user_check = self.backup_check(path_ini, db_munlist, kind = 'initial users')\n",
    "\n",
    "        if df_ini_user_check:\n",
    "            \n",
    "            if (len(db_ini_ls) == 0):\n",
    "                print('Database job: Initial users table is empty.')\n",
    "                print('Database job: Insert initial users backup into DB.')\n",
    "                self.df_to_postgres(conn, df_ini_users, initial_users_table)\n",
    "            else:\n",
    "                print('Database job: Initial users table is not empty.')\n",
    "                print('Data job: Compare initial users on DB and backup.')\n",
    "\n",
    "                df_ini_ls.sort()\n",
    "                db_ini_ls.sort()\n",
    "                \n",
    "                if df_ini_ls == db_ini_ls:\n",
    "                    print('Data job: initial users match.')\n",
    "                else:\n",
    "                    print('Database job: initial users do not match, drop and create initial users table.')\n",
    "                    #Create initial users table:\n",
    "                    print('Database job: Creating initial users table on DB.')\n",
    "                    self.query_SQL(queries_path + 'SMI_ini_users_table_creation.sql')\n",
    "                    \n",
    "                    #Initial users table insertion:\n",
    "                    print('Database job: Insert initial users back into DB.')\n",
    "                    self.df_to_postgres(conn, df_ini_users, initial_users_table)\n",
    "                    print('Database job: Initial users table inserted on DB.')\n",
    "        else:\n",
    "            self.scrap_users()\n",
    "\n",
    "    def insert_users(self):\n",
    "        '''\n",
    "        Function to insert users backup into DB.\n",
    "        params: self referenced, no params.\n",
    "        '''\n",
    "        db_usr_ls = self.fetchall_SQL(queries_path + 'SMI_usrs_database_screenName.sql')\n",
    "        path_usr = temp_data_path + 'db_users_' + db_users_bkp + '.json'\n",
    "        df_usr, df_usr_ls, df_usr_check = self.backup_check(path_usr, db_munlist, kind = 'users')\n",
    "\n",
    "        if df_usr_check:\n",
    "            \n",
    "            if (len(db_usr_ls) == 0):\n",
    "                print('Database job: Users table is empty.')\n",
    "                print('Database job: Insert users backup into DB.')\n",
    "                self.df_to_postgres(conn, df_usr, users_table)\n",
    "            else:\n",
    "                print('Database job: Users table is not empty.')\n",
    "                print('Data job: Compare users on db and backup.')\n",
    "\n",
    "                df_usr_ls.sort()\n",
    "                db_usr_ls.sort()\n",
    "                \n",
    "                if df_usr_ls == db_usr_ls:\n",
    "                    print('Data job: Users match.')\n",
    "                else:\n",
    "                    print('Database job: Users do not match, drop and create users table.')\n",
    "                    #Create initial users table:\n",
    "                    print('Database job: Creating users table on DB.')\n",
    "                    self.query_SQL(queries_path + 'SMI_usrs_table_creation.sql')\n",
    "                    \n",
    "                    #Initial users table insertion:\n",
    "                    print('Database job: Users back into DB.')\n",
    "                    self.df_to_postgres(conn, df_usr, users_table)\n",
    "                    print('Database job: Users table inserted on DB.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database job: Check if SMI schema exists.\n",
      "Database job: SMI schema exists on DB.\n",
      "Database job: Check if initial users table exist on DB.\n",
      "Database job: Initial users table exist on DB.\n",
      "Database job: Check if users table exist on DB.\n",
      "Database job: Users table exist on DB.\n",
      "Data job: Check if initial users backup exists.\n",
      "Data job: initial users backup exists. Loading file: ../data/db_ini_users_2022-02-08.json\n",
      "Data job: initial users backup from json file retrieved.\n",
      "Database job: Initial users table is not empty.\n",
      "Data job: Compare initial users on DB and backup.\n",
      "Data job: initial users match.\n",
      "Data job: Check if users backup exists.\n",
      "Data job: users backup exists. Loading file: ../data/db_users_2018-06-01.json\n",
      "Data Engineering job: Filtering location from backup users.\n",
      "Data Engineering job: Observations before filter: 673327\n",
      "Data Engineering job: Observations after filter: 240232\n",
      "Data job: users backup from json file retrieved.\n",
      "Database job: Users table is empty.\n",
      "Database job: Insert users backup into DB.\n"
     ]
    }
   ],
   "source": [
    "#Create class instance:\n",
    "dbcreate = DatabaseCreation(queries_path, conn, schema)\n",
    "\n",
    "## Check schema and tables:\n",
    "dbcreate.db_cs()\n",
    "\n",
    "## Check backups, tables and fill database:\n",
    "## Initial users:\n",
    "dbcreate.insert_ini_users()\n",
    "\n",
    "## Users:\n",
    "dbcreate.insert_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_corpus = '../../../../context/SMI/data/train_model/TASScorpus.json'\n",
    "with open(path_corpus, 'r') as f:\n",
    "    df = pd.json_normalize(json.load(f))\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "    df['content'] = df['content'].replace('\"','', regex=True)\n",
    "    df['content'] = df['content'].replace(',','', regex=True)\n",
    "    df['content'] = df['content'].replace(r'\\\\',' ', regex=True)\n",
    "    df['sentiment'] = df['sentiment'].replace(',','', regex=True)\n",
    "    df['content'] = df['content'].replace(r'\\r+|\\n+|\\t+','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweetid              object\n",
       "user                 object\n",
       "content              object\n",
       "date         datetime64[ns]\n",
       "lang                 object\n",
       "sentiment            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Perfectamente imperfecto. Besos RT @CiindyRomero: @AlejandroSanz no lo veo pero lo comienzo a sentir. Será perfecto! 355 240 275 355 262 277'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['tweetid'] == '172131381843984385'].iloc[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_corpus = '../../../../context/SMI/data/municipalities/munlist.json'\n",
    "with open(path_corpus, 'r') as f:\n",
    "    df = pd.DataFrame(json.load(f), columns=['location'])\n",
    "    df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a arnoia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a baña</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a bola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a capela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a cañiza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11696</th>\n",
       "      <td>álava</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11697</th>\n",
       "      <td>la tierra llana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11698</th>\n",
       "      <td>cruz de tenerife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11699</th>\n",
       "      <td>de tenerife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11700</th>\n",
       "      <td>de navarra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11701 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               location\n",
       "0              a arnoia\n",
       "1                a baña\n",
       "2                a bola\n",
       "3              a capela\n",
       "4              a cañiza\n",
       "...                 ...\n",
       "11696             álava\n",
       "11697   la tierra llana\n",
       "11698  cruz de tenerife\n",
       "11699       de tenerife\n",
       "11700        de navarra\n",
       "\n",
       "[11701 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_postgres(df, table, conn):\n",
    "    \"\"\"\n",
    "    Function to save dataframe into postgres with copy_from:\n",
    "    params:\n",
    "        - conn: database connection.\n",
    "        - df: pandas dataframe.\n",
    "        - table: database table.\n",
    "    \"\"\"\n",
    "    #Buffering the dataframe into memory:\n",
    "    buffer = StringIO()\n",
    "    df.to_csv(buffer, header=False, index=False)\n",
    "    buffer.seek(0)\n",
    "\n",
    "    #Copy cached dataframe into postgres:\n",
    "    cur = conn.cursor()\n",
    "    cur.copy_from(buffer, table, sep=\",\")\n",
    "    conn.commit()\n",
    "\n",
    "def treat_text(df, text_col, date_col = 'date', sent_col = 'sentiment'):\n",
    "    '''\n",
    "    Function to treat the corpus columns:\n",
    "    params:\n",
    "        - df: dataframe to treat.\n",
    "    Output: Dataframe treated.\n",
    "    '''\n",
    "\n",
    "    #Columns treatment:\n",
    "    \n",
    "    df[text_col] = df[text_col].replace(',','', regex=True)\n",
    "    df[text_col] = df[text_col].replace('\"','', regex=True)\n",
    "    df[text_col] = df[text_col].replace(r'\\\\',' ', regex=True)\n",
    "    df[text_col] = df[text_col].replace(r'\\r+|\\n+|\\t+','', regex=True)\n",
    "    df[text_col] = df[text_col].apply(lambda r: ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", r).split()))\n",
    "    \n",
    "    if date_col == 'date':\n",
    "        df[date_col] = pd.to_datetime(df[date_col])\n",
    "    if sent_col == 'sentiment':\n",
    "        df[sent_col] = df[sent_col].replace(',','', regex=True)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "def insert_tweets(path, dir, file):\n",
    "    \n",
    "    try:\n",
    "        with open(path + dir + '/' + file, 'r') as f:\n",
    "            df = pd.DataFrame(json.load(f))\n",
    "        df = treat_text(df, 'text', date_col = None, sent_col = None)\n",
    "        df_to_postgres(df, 'smi_tweets', conn)\n",
    "    except Exception as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tweets = '../../../../context/SMI/data/get_tweets/2015/DF_2015_12_22.json'\n",
    "with open(path_tweets, 'r') as f:\n",
    "    df = pd.DataFrame(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'] != '']\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google is working on an AI powered chat service that may or may not be a new Hangouts http flip it 4QSFq'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \", df['text'][0]).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15728/3799858874.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15728/3799858874.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(r)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.8/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(lambda r: ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",r).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "267337    0\n",
       "267338    0\n",
       "267339    0\n",
       "267340    0\n",
       "267341    0\n",
       "Name: retweets, Length: 267342, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['retweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing 2015\n",
      "importing DF_2015_11_21.json\n",
      "importing DF_2015_8_21.json\n",
      "importing DF_2015_12_21.json\n",
      "invalid input syntax for type numeric: \"Mobile's Workplace Role Continues to Grow http://www. emarketer.com/Article/Mobile s-Workplace-Role-Continues-Grow/1013365 … http://www. emarketer.com/Article/Mobile s-Workplace-Role-Continues-Grow/1013365 …\"\n",
      "CONTEXT:  COPY smi_tweets, line 1, column retweets: \"Mobile's Workplace Role Continues to Grow http://www. emarketer.com/Article/Mobile s-Workplace-Role-...\"\n",
      "\n",
      "importing DF_2015_7_21.json\n",
      "importing DF_2015_10_21.json\n",
      "importing DF_2015_9_21.json\n",
      "importing DF_2015_1_21.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6541/3176188181.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'importing'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0minsert_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_6541/1208598998.py\u001b[0m in \u001b[0;36minsert_tweets\u001b[0;34m(path, dir, file)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreat_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mdf_to_postgres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'smi_tweets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6541/1208598998.py\u001b[0m in \u001b[0;36mdf_to_postgres\u001b[0;34m(df, table, conn)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#Copy cached dataframe into postgres:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_tweets = '../../../../context/SMI/data/get_tweets/'\n",
    "dirs = os.listdir(path_tweets)\n",
    "\n",
    "for dir in dirs:\n",
    "    print(\"Importing\", dir)\n",
    "    files = os.listdir(path_tweets + dir + '/')\n",
    "    for file in files:\n",
    "        print('Importing' , file)\n",
    "        insert_tweets(path_tweets, dir, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT * FROM smi_schema.smi_tweets smic WHERE smic.user = %s\", (\"AiryMadness\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_fetch = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prueba = pd.DataFrame(db_fetch, columns = ['tweetid', 'user', 'content', 'date', 'lang', 'sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>769888103242797056</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>@babi_dark_ si ya las hago pero promocionarse ...</td>\n",
       "      <td>2016-08-28 13:23:22</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>770248677264883713</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>@Yuremonplsxd @PequeChikane Aquí habemos  me h...</td>\n",
       "      <td>2016-08-29 13:16:09</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770687689020600321</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>@AliceDesuDesu Legion&gt;Novia? Lo bonito es Legi...</td>\n",
       "      <td>2016-08-30 18:20:38</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769869979646828544</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>Echo de menos a Lexa  mis bragas ya no vuelan ...</td>\n",
       "      <td>2016-08-28 12:11:21</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>774583280758878208</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>es super cuqui  le pongo el dedo delante se su...</td>\n",
       "      <td>2016-09-10 12:20:19</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>773611786700525569</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>@Waidelai por eso  vente a la nuestra hemos te...</td>\n",
       "      <td>2016-09-07 19:59:57</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetid         user  \\\n",
       "0  769888103242797056  AiryMadness   \n",
       "1  770248677264883713  AiryMadness   \n",
       "2  770687689020600321  AiryMadness   \n",
       "3  769869979646828544  AiryMadness   \n",
       "4  774583280758878208  AiryMadness   \n",
       "5  773611786700525569  AiryMadness   \n",
       "\n",
       "                                             content                 date  \\\n",
       "0  @babi_dark_ si ya las hago pero promocionarse ...  2016-08-28 13:23:22   \n",
       "1  @Yuremonplsxd @PequeChikane Aquí habemos  me h...  2016-08-29 13:16:09   \n",
       "2  @AliceDesuDesu Legion>Novia? Lo bonito es Legi...  2016-08-30 18:20:38   \n",
       "3  Echo de menos a Lexa  mis bragas ya no vuelan ...  2016-08-28 12:11:21   \n",
       "4  es super cuqui  le pongo el dedo delante se su...  2016-09-10 12:20:19   \n",
       "5  @Waidelai por eso  vente a la nuestra hemos te...  2016-09-07 19:59:57   \n",
       "\n",
       "  lang sentiment  \n",
       "0   es         N  \n",
       "1   es         N  \n",
       "2   es         P  \n",
       "3   es         N  \n",
       "4   es         P  \n",
       "5   es         N  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>769888103242797056</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>@babi_dark_ si ya las hago pero promocionarse ...</td>\n",
       "      <td>2016-08-28 13:23:22</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>770248677264883713</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>@Yuremonplsxd @PequeChikane Aquí habemos  me h...</td>\n",
       "      <td>2016-08-29 13:16:09</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770687689020600321</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>@AliceDesuDesu Legion&gt;Novia? Lo bonito es Legi...</td>\n",
       "      <td>2016-08-30 18:20:38</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769869979646828544</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>Echo de menos a Lexa  mis bragas ya no vuelan ...</td>\n",
       "      <td>2016-08-28 12:11:21</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>774583280758878208</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>es super cuqui  le pongo el dedo delante se su...</td>\n",
       "      <td>2016-09-10 12:20:19</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>773611786700525569</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>@Waidelai por eso  vente a la nuestra hemos te...</td>\n",
       "      <td>2016-09-07 19:59:57</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetid         user  \\\n",
       "0  769888103242797056  AiryMadness   \n",
       "1  770248677264883713  AiryMadness   \n",
       "2  770687689020600321  AiryMadness   \n",
       "3  769869979646828544  AiryMadness   \n",
       "4  774583280758878208  AiryMadness   \n",
       "5  773611786700525569  AiryMadness   \n",
       "\n",
       "                                             content                 date  \\\n",
       "0  @babi_dark_ si ya las hago pero promocionarse ...  2016-08-28 13:23:22   \n",
       "1  @Yuremonplsxd @PequeChikane Aquí habemos  me h...  2016-08-29 13:16:09   \n",
       "2  @AliceDesuDesu Legion>Novia? Lo bonito es Legi...  2016-08-30 18:20:38   \n",
       "3  Echo de menos a Lexa  mis bragas ya no vuelan ...  2016-08-28 12:11:21   \n",
       "4  es super cuqui  le pongo el dedo delante se su...  2016-09-10 12:20:19   \n",
       "5  @Waidelai por eso  vente a la nuestra hemos te...  2016-09-07 19:59:57   \n",
       "\n",
       "  lang sentiment  \n",
       "0   es         N  \n",
       "1   es         N  \n",
       "2   es         P  \n",
       "3   es         N  \n",
       "4   es         P  \n",
       "5   es         N  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prueba[df_prueba['content'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prueba['content'] = df_prueba['content'].apply(lambda r: ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",r).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>769888103242797056</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>dark si ya las hago pero promocionarse es comp...</td>\n",
       "      <td>2016-08-28 13:23:22</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>770248677264883713</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>Aqu habemos me he saturado al leer eso idnwhy</td>\n",
       "      <td>2016-08-29 13:16:09</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770687689020600321</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>Legion Novia Lo bonito es Legi n novia en el p...</td>\n",
       "      <td>2016-08-30 18:20:38</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769869979646828544</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>Echo de menos a Lexa mis bragas ya no vuelan t...</td>\n",
       "      <td>2016-08-28 12:11:21</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>774583280758878208</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>es super cuqui le pongo el dedo delante se sub...</td>\n",
       "      <td>2016-09-10 12:20:19</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>773611786700525569</td>\n",
       "      <td>AiryMadness</td>\n",
       "      <td>por eso vente a la nuestra hemos tenido bronca...</td>\n",
       "      <td>2016-09-07 19:59:57</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetid         user  \\\n",
       "0  769888103242797056  AiryMadness   \n",
       "1  770248677264883713  AiryMadness   \n",
       "2  770687689020600321  AiryMadness   \n",
       "3  769869979646828544  AiryMadness   \n",
       "4  774583280758878208  AiryMadness   \n",
       "5  773611786700525569  AiryMadness   \n",
       "\n",
       "                                             content                 date  \\\n",
       "0  dark si ya las hago pero promocionarse es comp...  2016-08-28 13:23:22   \n",
       "1      Aqu habemos me he saturado al leer eso idnwhy  2016-08-29 13:16:09   \n",
       "2  Legion Novia Lo bonito es Legi n novia en el p...  2016-08-30 18:20:38   \n",
       "3  Echo de menos a Lexa mis bragas ya no vuelan t...  2016-08-28 12:11:21   \n",
       "4  es super cuqui le pongo el dedo delante se sub...  2016-09-10 12:20:19   \n",
       "5  por eso vente a la nuestra hemos tenido bronca...  2016-09-07 19:59:57   \n",
       "\n",
       "  lang sentiment  \n",
       "0   es         N  \n",
       "1   es         N  \n",
       "2   es         P  \n",
       "3   es         N  \n",
       "4   es         P  \n",
       "5   es         N  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT * FROM smi_schema.smi_munlist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_fetch = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "munlist = pd.DataFrame(db_fetch, columns = ['location'])['location'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean_loc(name):\n",
    "    '''\n",
    "    Function to remove accents from an alphanumeric string:\n",
    "    params:\n",
    "        - name: character string.\n",
    "    Output: string without accents.\n",
    "    '''\n",
    "        #Define replacements (possible accents or other special char)\n",
    "    replacements = (\n",
    "            (\"á\", \"a\"),\n",
    "            (\"é\", \"e\"),\n",
    "            (\"í\", \"i\"),\n",
    "            (\"ó\", \"o\"),\n",
    "            (\"ú\", \"u\"),\n",
    "            (\"ñ\", 'n'),\n",
    "            (\"à\", \"a\"),\n",
    "            (\"è\", \"e\"),\n",
    "            (\"ì\", \"i\"),\n",
    "            (\"ò\", \"o\"),\n",
    "            (\"ù\", \"u\"),\n",
    "            (\"ä\", 'a'),\n",
    "            (\"ë\", \"e\"),\n",
    "            (\"ï\", \"i\"),\n",
    "            (\"ö\", \"o\"),\n",
    "            (\"ü\", \"u\"),\n",
    "        )\n",
    "        #Replace with tuple:\n",
    "    for a, b in replacements:\n",
    "        name = name.replace(a, b).replace(a.upper(), b.upper())\n",
    "    return(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "munlist_treated = [text_clean_loc(mun.lower().replace(',', '')) for mun in munlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a arnoia',\n",
       " 'a bana',\n",
       " 'a bola',\n",
       " 'a capela',\n",
       " 'a caniza',\n",
       " 'a coruna',\n",
       " 'a estrada',\n",
       " 'a fonsagrada',\n",
       " 'a guarda',\n",
       " 'a gudina',\n",
       " 'a illa de arousa',\n",
       " 'a lama',\n",
       " 'a laracha',\n",
       " 'a merca',\n",
       " 'a mezquita',\n",
       " 'a pastoriza',\n",
       " 'a peroxa',\n",
       " 'a pobra de trives',\n",
       " 'a pobra do brollon',\n",
       " 'a pobra do caraminal',\n",
       " 'a pontenova',\n",
       " 'a rua',\n",
       " 'a teixeira',\n",
       " 'a veiga',\n",
       " 'ababuj',\n",
       " 'abades',\n",
       " 'abadino',\n",
       " 'abadia',\n",
       " 'abadin',\n",
       " 'abajas',\n",
       " 'abaltzisketa',\n",
       " 'abanilla',\n",
       " 'abanto',\n",
       " 'abarca de campos',\n",
       " 'abaran',\n",
       " 'abegondo',\n",
       " 'abejar',\n",
       " 'abejuela',\n",
       " 'abella de la conca',\n",
       " 'abengibre',\n",
       " 'abenojar',\n",
       " 'aberin',\n",
       " 'abertura',\n",
       " 'abezames',\n",
       " 'abia de la obispalia',\n",
       " 'abia de las torres',\n",
       " 'abiego',\n",
       " 'abizanda',\n",
       " 'abla',\n",
       " 'ablanque',\n",
       " 'ablitas',\n",
       " 'abrera',\n",
       " 'abrucena',\n",
       " 'abusejo',\n",
       " 'abaigar',\n",
       " 'abanades',\n",
       " 'abarzuza',\n",
       " 'acebedo',\n",
       " 'acedera',\n",
       " 'acehuche',\n",
       " 'aceituna',\n",
       " 'acered',\n",
       " 'aceuchal',\n",
       " 'adahuesca',\n",
       " 'adalia',\n",
       " 'adamuz',\n",
       " 'adanero',\n",
       " 'adeje',\n",
       " 'ademuz',\n",
       " 'adios',\n",
       " 'adobes',\n",
       " 'ador',\n",
       " 'adra',\n",
       " 'adrada de haza',\n",
       " 'adrada de piron',\n",
       " 'adradas',\n",
       " 'adrados',\n",
       " 'adsubia',\n",
       " 'aduna',\n",
       " 'agaete',\n",
       " 'agallas',\n",
       " 'agolada',\n",
       " 'agoncillo',\n",
       " 'agost',\n",
       " 'agramunt',\n",
       " 'agres',\n",
       " 'agron',\n",
       " 'aguadulce',\n",
       " 'aguaron',\n",
       " 'aguas candidas',\n",
       " 'aguasal',\n",
       " 'aguaton',\n",
       " 'aguaviva',\n",
       " 'agudo',\n",
       " 'aguilafuente',\n",
       " 'aguilar de bureba',\n",
       " 'aguilar de campoo',\n",
       " 'aguilar de campos',\n",
       " 'aguilar de codes',\n",
       " 'aguilar de segarra',\n",
       " 'aguilar de la frontera',\n",
       " 'aguilar del alfambra',\n",
       " 'aguilar del rio alhama',\n",
       " 'aguilon',\n",
       " 'agullana',\n",
       " 'agullent',\n",
       " 'agulo',\n",
       " 'agon',\n",
       " 'aguero',\n",
       " 'aguimes',\n",
       " 'ahigal',\n",
       " 'ahigal de villarino',\n",
       " 'ahigal de los aceiteros',\n",
       " 'ahillones',\n",
       " 'aia',\n",
       " 'aielo de malferit',\n",
       " 'aielo de rugat',\n",
       " 'aiguafreda',\n",
       " 'aiguamurcia',\n",
       " 'aiguaviva',\n",
       " 'aigues',\n",
       " 'ainzon',\n",
       " 'aisa',\n",
       " 'aitona',\n",
       " 'aizarnazabal',\n",
       " 'ajalvir',\n",
       " 'ajamil de cameros',\n",
       " 'ajangiz',\n",
       " 'ajofrin',\n",
       " 'alacon',\n",
       " 'aladren',\n",
       " 'alaejos',\n",
       " 'alagon',\n",
       " 'alagon del rio',\n",
       " 'alaior',\n",
       " 'alajero',\n",
       " 'alameda',\n",
       " 'alameda de la sagra',\n",
       " 'alameda del valle',\n",
       " 'alamedilla',\n",
       " 'alamillo',\n",
       " 'alaminos',\n",
       " 'alange',\n",
       " 'alanis',\n",
       " 'alaquas',\n",
       " 'alar del rey',\n",
       " 'alaraz',\n",
       " 'alarba',\n",
       " 'alarcon',\n",
       " 'alarilla',\n",
       " 'alaro',\n",
       " 'alatoz',\n",
       " 'alba',\n",
       " 'alba de cerrato',\n",
       " 'alba de tormes',\n",
       " 'alba de yeltes',\n",
       " 'albacete',\n",
       " 'albaida',\n",
       " 'albaida del aljarafe',\n",
       " 'albal',\n",
       " 'albaladejo',\n",
       " 'albaladejo del cuende',\n",
       " 'albalat de la ribera',\n",
       " 'albalat dels sorells',\n",
       " 'albalat dels tarongers',\n",
       " 'albalate de cinca',\n",
       " 'albalate de zorita',\n",
       " 'albalate de las nogueras',\n",
       " 'albalate del arzobispo',\n",
       " 'albalatillo',\n",
       " 'albala',\n",
       " 'albanchez de magina',\n",
       " 'albanya',\n",
       " 'albares',\n",
       " 'albarracin',\n",
       " 'albarreal de tajo',\n",
       " 'albatana',\n",
       " 'albatera',\n",
       " 'albatarrec',\n",
       " 'albelda',\n",
       " 'albelda de iregua',\n",
       " 'albendea',\n",
       " 'albendiego',\n",
       " 'albentosa',\n",
       " 'alberic',\n",
       " 'alberite',\n",
       " 'alberite de san juan',\n",
       " 'albero alto',\n",
       " 'albero bajo',\n",
       " 'alberuela de tubo',\n",
       " 'albesa',\n",
       " 'albeta',\n",
       " 'albillos',\n",
       " 'albinyana',\n",
       " 'albiztur',\n",
       " 'albocasser',\n",
       " 'alboloduy',\n",
       " 'albolote',\n",
       " 'albondon',\n",
       " 'albons',\n",
       " 'alborache',\n",
       " 'alboraia',\n",
       " 'alborea',\n",
       " 'alborge',\n",
       " 'albornos',\n",
       " 'albox',\n",
       " 'albudeite',\n",
       " 'albuixech',\n",
       " 'alburquerque',\n",
       " 'albunol',\n",
       " 'albunuelas',\n",
       " 'albunan',\n",
       " 'albanchez',\n",
       " 'alcabon',\n",
       " 'alcadozo',\n",
       " 'alcaine',\n",
       " 'alcalali',\n",
       " 'alcala de xivert',\n",
       " 'alcala de ebro',\n",
       " 'alcala de guadaira',\n",
       " 'alcala de gurrea',\n",
       " 'alcala de henares',\n",
       " 'alcala de moncayo',\n",
       " 'alcala de la selva',\n",
       " 'alcala de la vega',\n",
       " 'alcala de los gazules',\n",
       " 'alcala del jucar',\n",
       " 'alcala del obispo',\n",
       " 'alcala del rio',\n",
       " 'alcala del valle',\n",
       " 'alcala la real',\n",
       " 'alcampell',\n",
       " 'alcanadre',\n",
       " 'alcanar',\n",
       " 'alcantarilla',\n",
       " 'alcantud',\n",
       " 'alcano',\n",
       " 'alcaracejos',\n",
       " 'alcaraz',\n",
       " 'alcarras',\n",
       " 'alcaucin',\n",
       " 'alcaudete',\n",
       " 'alcaudete de la jara',\n",
       " 'alcazaren',\n",
       " 'alcanices',\n",
       " 'alcaniz',\n",
       " 'alcanizo',\n",
       " 'alcobendas',\n",
       " 'alcocer',\n",
       " 'alcocer de planes',\n",
       " 'alcocero de mola',\n",
       " 'alcohujate',\n",
       " 'alcolea',\n",
       " 'alcolea de calatrava',\n",
       " 'alcolea de cinca',\n",
       " 'alcolea de tajo',\n",
       " 'alcolea de las penas',\n",
       " 'alcolea del pinar',\n",
       " 'alcolea del rio',\n",
       " 'alcoleja',\n",
       " 'alcoletge',\n",
       " 'alcollarin',\n",
       " 'alconaba',\n",
       " 'alconada',\n",
       " 'alconada de maderuelo',\n",
       " 'alconchel',\n",
       " 'alconchel de ariza',\n",
       " 'alconchel de la estrella',\n",
       " 'alconera',\n",
       " 'alcorcon',\n",
       " 'alcorisa',\n",
       " 'alcoroches',\n",
       " 'alcover',\n",
       " 'alcoy',\n",
       " 'alcubierre',\n",
       " 'alcubilla de avellaneda',\n",
       " 'alcubilla de nogales',\n",
       " 'alcubilla de las penas',\n",
       " 'alcubillas',\n",
       " 'alcublas',\n",
       " 'alcudia de monteagud',\n",
       " 'alcudia de veo',\n",
       " 'alcuescar',\n",
       " 'alcantera de xuquer',\n",
       " 'alcasser',\n",
       " 'alcantara',\n",
       " 'alcazar de san juan',\n",
       " 'alcazar del rey',\n",
       " 'alcontar',\n",
       " 'alcudia',\n",
       " 'aldaia',\n",
       " 'aldea real',\n",
       " 'aldea de san miguel',\n",
       " 'aldea del cano',\n",
       " 'aldea del fresno',\n",
       " 'aldea del obispo',\n",
       " 'aldea del rey',\n",
       " 'aldea en cabo',\n",
       " 'aldeacentenera',\n",
       " 'aldeacipreste',\n",
       " 'aldeadavila de la ribera',\n",
       " 'aldealafuente',\n",
       " 'aldealcorvo',\n",
       " 'aldealengua',\n",
       " 'aldealengua de pedraza',\n",
       " 'aldealengua de santa maria',\n",
       " 'aldealices',\n",
       " 'aldealpozo',\n",
       " 'aldealsenor',\n",
       " 'aldeamayor de san martin',\n",
       " 'aldeanueva de barbarroya',\n",
       " 'aldeanueva de ebro',\n",
       " 'aldeanueva de figueroa',\n",
       " 'aldeanueva de guadalajara',\n",
       " 'aldeanueva de san bartolome',\n",
       " 'aldeanueva de santa cruz',\n",
       " 'aldeanueva de la serrezuela',\n",
       " 'aldeanueva de la sierra',\n",
       " 'aldeanueva de la vera',\n",
       " 'aldeanueva del camino',\n",
       " 'aldeanueva del codonal',\n",
       " 'aldeaquemada',\n",
       " 'aldearrodrigo',\n",
       " 'aldearrubia',\n",
       " 'aldeaseca',\n",
       " 'aldeaseca de alba',\n",
       " 'aldeaseca de la frontera',\n",
       " 'aldeasona',\n",
       " 'aldeatejada',\n",
       " 'aldeavieja de tormes',\n",
       " 'aldehorno',\n",
       " 'aldehuela de jerte',\n",
       " 'aldehuela de liestos',\n",
       " 'aldehuela de perianez',\n",
       " 'aldehuela de yeltes',\n",
       " 'aldehuela de la boveda',\n",
       " 'aldehuela del codonal',\n",
       " 'aldeire',\n",
       " 'aldeonte',\n",
       " 'aldover',\n",
       " 'aledo',\n",
       " 'alegia',\n",
       " 'alella',\n",
       " 'alentisque',\n",
       " 'alerre',\n",
       " 'alesanco',\n",
       " 'aleson',\n",
       " 'alfacar',\n",
       " 'alfafar',\n",
       " 'alfafara',\n",
       " 'alfajarin',\n",
       " 'alfambra',\n",
       " 'alfamen',\n",
       " 'alfara de carles',\n",
       " 'alfara de la baronia',\n",
       " 'alfara del patriarca',\n",
       " 'alfaraz de sayago',\n",
       " 'alfarnate',\n",
       " 'alfarnatejo',\n",
       " 'alfaro',\n",
       " 'alfarp',\n",
       " 'alfarrasi',\n",
       " 'alfarras',\n",
       " 'alfauir',\n",
       " 'alfondeguilla',\n",
       " 'alforja',\n",
       " 'alforque',\n",
       " 'alfoz',\n",
       " 'alfoz de bricia',\n",
       " 'alfoz de lloredo',\n",
       " 'alfoz de quintanaduenas',\n",
       " 'alfoz de santa gadea',\n",
       " 'alfantega',\n",
       " 'alfes',\n",
       " 'algadefe',\n",
       " 'algaida',\n",
       " 'algar',\n",
       " 'algar de mesa',\n",
       " 'algar de palancia',\n",
       " 'algarinejo',\n",
       " 'algarra',\n",
       " 'algarrobo',\n",
       " 'algatocin',\n",
       " 'algeciras',\n",
       " 'algemesi',\n",
       " 'algerri',\n",
       " 'algete',\n",
       " 'algimia de alfara',\n",
       " 'algimia de almonacid',\n",
       " 'alginet',\n",
       " 'algodonales',\n",
       " 'algodre',\n",
       " 'algora',\n",
       " 'algorfa',\n",
       " 'alguaire',\n",
       " 'alguazas',\n",
       " 'alguena',\n",
       " 'algamitas',\n",
       " 'alhabia',\n",
       " 'alhama de almeria',\n",
       " 'alhama de aragon',\n",
       " 'alhama de granada',\n",
       " 'alhama de murcia',\n",
       " 'alhaurin de la torre',\n",
       " 'alhaurin el grande',\n",
       " 'alhendin',\n",
       " 'aliaga',\n",
       " 'aliaguilla',\n",
       " 'alicante',\n",
       " 'alicun',\n",
       " 'alicun de ortega',\n",
       " 'alija del infantado',\n",
       " 'alins',\n",
       " 'alique',\n",
       " 'aliseda',\n",
       " 'aliud',\n",
       " 'alio',\n",
       " 'aljaraque',\n",
       " 'aljucen',\n",
       " 'alkiza',\n",
       " 'allande',\n",
       " 'allariz',\n",
       " 'allepuz',\n",
       " 'aller',\n",
       " 'allo',\n",
       " 'alloza',\n",
       " 'allueva',\n",
       " 'allin',\n",
       " 'almacelles',\n",
       " 'almadenejos',\n",
       " 'almadrones',\n",
       " 'almaden',\n",
       " 'almaden de la plata',\n",
       " 'almagro',\n",
       " 'almajano',\n",
       " 'almaluez',\n",
       " 'almansa',\n",
       " 'almanza',\n",
       " 'almaraz',\n",
       " 'almaraz de duero',\n",
       " 'almargen',\n",
       " 'almarza',\n",
       " 'almarza de cameros',\n",
       " 'almatret',\n",
       " 'almazul',\n",
       " 'almazan',\n",
       " 'almedina',\n",
       " 'almedinilla',\n",
       " 'almedijar',\n",
       " 'almegijar',\n",
       " 'almeida de sayago',\n",
       " 'almenar',\n",
       " 'almenar de soria',\n",
       " 'almenara',\n",
       " 'almenara de adaja',\n",
       " 'almenara de tormes',\n",
       " 'almendra',\n",
       " 'almendral',\n",
       " 'almendral de la canada',\n",
       " 'almendralejo',\n",
       " 'almendros',\n",
       " 'almensilla',\n",
       " 'almeria',\n",
       " 'almisera',\n",
       " 'almochuel',\n",
       " 'almodovar del campo',\n",
       " 'almodovar del pinar',\n",
       " 'almodovar del rio',\n",
       " 'almoguera',\n",
       " 'almogia',\n",
       " 'almohaja',\n",
       " 'almoharin',\n",
       " 'almoines',\n",
       " 'almonacid de toledo',\n",
       " 'almonacid de zorita',\n",
       " 'almonacid de la cuba',\n",
       " 'almonacid de la sierra',\n",
       " 'almonacid del marquesado',\n",
       " 'almonaster la real',\n",
       " 'almonte',\n",
       " 'almoradi',\n",
       " 'almorox',\n",
       " 'almoster',\n",
       " 'almudaina',\n",
       " 'almudevar',\n",
       " 'almunia de san juan',\n",
       " 'almuniente',\n",
       " 'almuradiel',\n",
       " 'almussafes',\n",
       " 'almunecar',\n",
       " 'almassera',\n",
       " 'almachar',\n",
       " 'almocita',\n",
       " 'alobras',\n",
       " 'alocen',\n",
       " 'alonsotegi',\n",
       " 'alosno',\n",
       " 'alovera',\n",
       " 'alozaina',\n",
       " 'alp',\n",
       " 'alpandeire',\n",
       " 'alpanseque',\n",
       " 'alpartir',\n",
       " 'alpedrete',\n",
       " 'alpens',\n",
       " 'alpera',\n",
       " 'alpenes',\n",
       " 'alpicat',\n",
       " 'alpuente',\n",
       " 'alpujarra de la sierra',\n",
       " 'alquerias del nino perdido',\n",
       " 'alquife',\n",
       " 'alquezar',\n",
       " 'alsodux',\n",
       " 'alt aneu',\n",
       " 'altable',\n",
       " 'altafulla',\n",
       " 'altarejos',\n",
       " 'altea',\n",
       " 'altorricon',\n",
       " 'altura',\n",
       " 'altzaga',\n",
       " 'altzo',\n",
       " 'alustante',\n",
       " 'alzira',\n",
       " 'alas i cerc',\n",
       " 'alajar',\n",
       " 'alia',\n",
       " 'alos de balaguer',\n",
       " 'amavida',\n",
       " 'amayuelas de arriba',\n",
       " 'ambel',\n",
       " 'ambite',\n",
       " 'amer',\n",
       " 'ameyugo',\n",
       " 'amezketa',\n",
       " 'amieva',\n",
       " 'amoeiro',\n",
       " 'amorebieta-etxano',\n",
       " 'amoroto',\n",
       " 'amposta',\n",
       " 'ampudia',\n",
       " 'ampuero',\n",
       " 'amurrio',\n",
       " 'amusco',\n",
       " 'amusquillo',\n",
       " 'amescoa baja',\n",
       " 'anadon',\n",
       " 'anaya',\n",
       " 'anaya de alba',\n",
       " 'anchuelo',\n",
       " 'anchuras',\n",
       " 'andavias',\n",
       " 'andilla',\n",
       " 'andoain',\n",
       " 'andorra (teruel)',\n",
       " 'andosilla',\n",
       " 'andratx',\n",
       " 'andujar',\n",
       " 'anento',\n",
       " 'anglesola',\n",
       " 'anguciana',\n",
       " 'anguiano',\n",
       " 'anguix',\n",
       " 'angon',\n",
       " 'angues',\n",
       " 'anievas',\n",
       " 'aninon',\n",
       " 'anna',\n",
       " 'anoeta',\n",
       " 'anquela del ducado',\n",
       " 'anquela del pedregal',\n",
       " 'anso',\n",
       " 'antas',\n",
       " 'antas de ulla',\n",
       " 'antella',\n",
       " 'antequera',\n",
       " 'antigua',\n",
       " 'antiguedad',\n",
       " 'antillon',\n",
       " 'antzuola',\n",
       " 'anue',\n",
       " 'arabayona de mogica',\n",
       " 'aracena',\n",
       " 'arafo',\n",
       " 'aragues del puerto',\n",
       " 'arahal',\n",
       " 'arahuetes',\n",
       " 'araitz',\n",
       " 'arakaldo',\n",
       " 'arakil',\n",
       " 'arama',\n",
       " 'aramaio',\n",
       " 'arancon',\n",
       " 'aranda de duero',\n",
       " 'aranda de moncayo',\n",
       " 'arandilla',\n",
       " 'arandilla del arroyo',\n",
       " 'aranga',\n",
       " 'aranguren',\n",
       " 'aranjuez',\n",
       " 'arano',\n",
       " 'arantza',\n",
       " 'arantzazu',\n",
       " 'aranzueque',\n",
       " 'arapiles',\n",
       " 'aras',\n",
       " 'aras de los olmos',\n",
       " 'arauzo de miel',\n",
       " 'arauzo de salce',\n",
       " 'arauzo de torre',\n",
       " 'aranuel',\n",
       " 'arbancon',\n",
       " 'arbeca',\n",
       " 'arbeteta',\n",
       " 'arbizu',\n",
       " 'arbo',\n",
       " 'arboleas',\n",
       " 'arboli',\n",
       " 'arbucies',\n",
       " 'arcas del villar',\n",
       " 'arcediano',\n",
       " 'arcenillas',\n",
       " 'archena',\n",
       " 'archidona',\n",
       " 'arcicollar',\n",
       " 'arconada',\n",
       " 'arcones',\n",
       " 'arcos',\n",
       " 'arcos de jalon',\n",
       " 'arcos de la frontera',\n",
       " 'arcos de la polvorosa',\n",
       " 'arcos de la sierra',\n",
       " 'arcos de las salinas',\n",
       " 'ardales',\n",
       " 'ardisa',\n",
       " 'ardon',\n",
       " 'areatza',\n",
       " 'arellano',\n",
       " 'arenales de san gregorio',\n",
       " 'arenas de iguna',\n",
       " 'arenas de san juan',\n",
       " 'arenas del rey',\n",
       " 'arenillas',\n",
       " 'arenillas de riopisuerga',\n",
       " 'arens de lledo',\n",
       " 'arenys de mar',\n",
       " 'arenys de munt',\n",
       " 'arenzana de abajo',\n",
       " 'arenzana de arriba',\n",
       " 'ares del maestrat',\n",
       " 'areso',\n",
       " 'aretxabaleta',\n",
       " 'arevalillo',\n",
       " 'arevalillo de cega',\n",
       " 'argamasilla de alba',\n",
       " 'argamasilla de calatrava',\n",
       " 'arganda del rey',\n",
       " 'arganza',\n",
       " 'argavieso',\n",
       " 'arganin',\n",
       " 'argecilla',\n",
       " 'argelaguer',\n",
       " 'argelita',\n",
       " 'argente',\n",
       " 'argentona',\n",
       " 'argençola',\n",
       " 'argonos',\n",
       " 'arguedas',\n",
       " 'arguis',\n",
       " 'arguisuelas',\n",
       " 'argujillo',\n",
       " 'arges',\n",
       " 'aria',\n",
       " 'ariany',\n",
       " 'aribe',\n",
       " 'arico',\n",
       " 'arija',\n",
       " 'ariza',\n",
       " 'arino',\n",
       " 'arjona',\n",
       " 'arjonilla',\n",
       " 'arlanzon',\n",
       " 'armallones',\n",
       " 'armananzas',\n",
       " 'armenteros',\n",
       " 'armilla',\n",
       " 'arminon',\n",
       " 'armuna',\n",
       " 'armuna de almanzora',\n",
       " 'armuna de tajuna',\n",
       " 'arnedillo',\n",
       " 'arnedo',\n",
       " 'arnes',\n",
       " 'arnuero',\n",
       " 'aroche',\n",
       " 'arona',\n",
       " 'arquillinos',\n",
       " 'arquillos',\n",
       " 'arrabalde',\n",
       " 'arraia-maeztu',\n",
       " 'arrancacepas',\n",
       " 'arrankudiaga',\n",
       " 'arrasate',\n",
       " 'arratzu',\n",
       " 'arraya de oca',\n",
       " 'arrazua-ubarrundia',\n",
       " 'arrecife',\n",
       " 'arredondo',\n",
       " 'arres',\n",
       " 'arriate',\n",
       " 'arrigorriaga',\n",
       " 'arroba de los montes',\n",
       " 'arroyo de san servan',\n",
       " 'arroyo de la encomienda',\n",
       " 'arroyo de la luz',\n",
       " 'arroyo de las fraguas',\n",
       " 'arroyo del ojanco',\n",
       " 'arroyomolinos',\n",
       " 'arroyomolinos de leon',\n",
       " 'arroyomolinos de la vera',\n",
       " 'arruazu',\n",
       " 'arroniz',\n",
       " 'arrubal',\n",
       " 'arseguel',\n",
       " 'artajona',\n",
       " 'artana',\n",
       " 'artazu',\n",
       " 'arteixo',\n",
       " 'artenara',\n",
       " 'artesa de lleida',\n",
       " 'artesa de segre',\n",
       " 'artieda',\n",
       " 'artzentales',\n",
       " 'artziniega',\n",
       " 'arta',\n",
       " 'artes',\n",
       " 'arucas',\n",
       " 'arzua',\n",
       " 'arandiga',\n",
       " 'aren',\n",
       " 'arevalo',\n",
       " 'arevalo de la sierra',\n",
       " 'arins',\n",
       " 'as neves',\n",
       " 'as nogais',\n",
       " 'as pontes de garcia rodriguez',\n",
       " 'as somozas',\n",
       " 'asco',\n",
       " 'aspa',\n",
       " 'aspariegos',\n",
       " 'asparrena',\n",
       " 'aspe',\n",
       " 'asteasu',\n",
       " 'astigarraga',\n",
       " 'astorga',\n",
       " 'astudillo',\n",
       " 'asin',\n",
       " 'atajate',\n",
       " 'atalaya del canavate',\n",
       " 'atanzon',\n",
       " 'atapuerca',\n",
       " 'ataquines',\n",
       " 'atarfe',\n",
       " 'ataun',\n",
       " 'ateca',\n",
       " 'atez',\n",
       " 'atienza',\n",
       " 'atxondo',\n",
       " \"atzeneta d'albaida\",\n",
       " 'atzeneta del maestrat',\n",
       " 'aulesti',\n",
       " 'ausejo',\n",
       " 'ausejo de la sierra',\n",
       " 'autilla del pino',\n",
       " 'autillo de campos',\n",
       " 'autol',\n",
       " 'aunon',\n",
       " 'aveinte',\n",
       " 'avellaneda',\n",
       " 'avellanosa de muno',\n",
       " 'aviles',\n",
       " 'avinyonet de puigventos',\n",
       " 'avinyonet del penedes',\n",
       " 'avinyo',\n",
       " 'avia',\n",
       " 'avion',\n",
       " 'ayala/aiara',\n",
       " 'ayamonte',\n",
       " 'ayerbe',\n",
       " 'ayllon',\n",
       " 'ayora',\n",
       " 'ayoo de vidriales',\n",
       " 'ayuela',\n",
       " 'ayodar',\n",
       " 'azagra',\n",
       " 'azaila',\n",
       " 'azanuy-alins',\n",
       " 'azara',\n",
       " 'azkoitia',\n",
       " 'azlor',\n",
       " 'aznalcazar',\n",
       " 'aznalcollar',\n",
       " 'azofra',\n",
       " 'azpeitia',\n",
       " 'azuaga',\n",
       " 'azuara',\n",
       " 'azuelo',\n",
       " 'azuqueca de henares',\n",
       " 'azutan',\n",
       " 'azuebar',\n",
       " 'ain',\n",
       " 'ainsa-sobrarbe',\n",
       " 'anana',\n",
       " 'ane',\n",
       " 'anora',\n",
       " 'anorbe',\n",
       " 'anover de tajo',\n",
       " 'anover de tormes',\n",
       " 'anon de moncayo',\n",
       " 'aýna',\n",
       " 'babilafuente',\n",
       " 'bacares',\n",
       " 'badajoz',\n",
       " 'badalona',\n",
       " 'badaran',\n",
       " 'badia del valles',\n",
       " 'badolatosa',\n",
       " 'badules',\n",
       " 'badia del valles',\n",
       " 'baena',\n",
       " 'baeza',\n",
       " 'baga',\n",
       " 'bagues',\n",
       " 'bahabon',\n",
       " 'bahabon de esgueva',\n",
       " 'baides',\n",
       " 'bailo',\n",
       " 'bailen',\n",
       " 'baiona',\n",
       " 'baix pallars',\n",
       " 'bakaiku',\n",
       " 'bakio',\n",
       " 'balaguer',\n",
       " 'balazote',\n",
       " 'balboa',\n",
       " 'balconchan',\n",
       " 'baldellou',\n",
       " 'baleira',\n",
       " 'balenya',\n",
       " 'baliarrain',\n",
       " 'ballesteros de calatrava',\n",
       " 'ballobar',\n",
       " 'balmaseda',\n",
       " 'balones',\n",
       " 'balsa de ves',\n",
       " 'balsareny',\n",
       " 'baltanas',\n",
       " 'baltar',\n",
       " 'banastas',\n",
       " 'bande',\n",
       " 'banyalbufar',\n",
       " 'banyeres de mariola',\n",
       " 'banyeres del penedes',\n",
       " 'banyoles',\n",
       " 'baquerin de campos',\n",
       " 'barajas de melo',\n",
       " 'barakaldo',\n",
       " 'baralla',\n",
       " 'baraona',\n",
       " 'baranain',\n",
       " 'barbadillo',\n",
       " 'barbadillo de herreros',\n",
       " 'barbadillo del mercado',\n",
       " 'barbadillo del pez',\n",
       " 'barbadas',\n",
       " 'barbalos',\n",
       " 'barbarin',\n",
       " 'barbastro',\n",
       " 'barbate',\n",
       " 'barbens',\n",
       " 'barbera de la conca',\n",
       " 'barbera del valles',\n",
       " 'barbolla',\n",
       " 'barbues',\n",
       " 'barbunales',\n",
       " 'barca',\n",
       " 'barcarrota',\n",
       " 'barcelona',\n",
       " 'barceo',\n",
       " 'barchin del hoyo',\n",
       " 'barcial de la loma',\n",
       " 'barcial del barco',\n",
       " 'barcience',\n",
       " 'barcones',\n",
       " 'bardallur',\n",
       " 'bareyo',\n",
       " 'bargas',\n",
       " 'bargota',\n",
       " 'barillas',\n",
       " 'barjas',\n",
       " 'barlovento',\n",
       " 'barracas',\n",
       " 'barrachina',\n",
       " 'barrado',\n",
       " 'barrax',\n",
       " 'barreiros',\n",
       " 'barrika',\n",
       " 'barrio de muno',\n",
       " 'barriopedro',\n",
       " 'barrios de colina',\n",
       " 'barro',\n",
       " 'barroman',\n",
       " 'barruecopardo',\n",
       " 'barruelo de santullan',\n",
       " 'barruelo del valle',\n",
       " 'barrundia',\n",
       " 'barx',\n",
       " 'barxeta',\n",
       " 'barasoain',\n",
       " 'basaburua',\n",
       " 'basardilla',\n",
       " 'basauri',\n",
       " 'basconcillos del tozo',\n",
       " 'bascunana',\n",
       " 'bascunana de san pedro',\n",
       " 'bassella',\n",
       " 'batea',\n",
       " 'baterno',\n",
       " 'batres',\n",
       " 'bausen',\n",
       " 'bayarque',\n",
       " 'bayubas de abajo',\n",
       " 'bayubas de arriba',\n",
       " 'bayarcal',\n",
       " 'baza',\n",
       " 'baztan',\n",
       " 'baells',\n",
       " 'banares',\n",
       " 'banobarez',\n",
       " 'banos de ebro/manueta',\n",
       " 'banos de molgas',\n",
       " 'bernedo',\n",
       " 'banos de montemayor',\n",
       " 'banos de rioja',\n",
       " 'banos de rio tobia',\n",
       " 'banos de tajo',\n",
       " 'banos de valdearados',\n",
       " 'banos de la encina',\n",
       " 'banuelos',\n",
       " 'banuelos de bureba',\n",
       " 'banon',\n",
       " 'bea',\n",
       " 'beade',\n",
       " 'beamud',\n",
       " 'beariz',\n",
       " 'beas',\n",
       " 'beas de granada',\n",
       " 'beas de guadix',\n",
       " 'beas de segura',\n",
       " 'beasain',\n",
       " 'becedas',\n",
       " 'becedillas',\n",
       " 'beceite',\n",
       " 'becerrea',\n",
       " 'becerril de campos',\n",
       " 'becerril de la sierra',\n",
       " 'becilla de valderaduey',\n",
       " 'bedia',\n",
       " 'bedmar y garciez',\n",
       " 'begonte',\n",
       " 'begues',\n",
       " 'begur',\n",
       " 'begijar',\n",
       " 'beintza-labaien',\n",
       " 'beire',\n",
       " 'beires',\n",
       " 'beizama',\n",
       " 'bejis',\n",
       " 'belalcazar',\n",
       " 'belascoain',\n",
       " 'belauntza',\n",
       " 'belbimbre',\n",
       " 'belchite',\n",
       " 'belena',\n",
       " 'belianes',\n",
       " 'belinchon',\n",
       " \"bell-lloc d'urgell\",\n",
       " 'bellaguarda',\n",
       " \"bellcaire d'emporda\",\n",
       " \"bellcaire d'urgell\",\n",
       " \"bellmunt d'urgell\",\n",
       " 'bellmunt del priorat',\n",
       " 'bello',\n",
       " 'bellprat',\n",
       " 'bellpuig',\n",
       " 'bellreguard',\n",
       " 'bellvei',\n",
       " 'bellver de cerdanya',\n",
       " 'bellvis',\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "munlist_treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
